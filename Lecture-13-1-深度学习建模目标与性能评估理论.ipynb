{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9768e2-2ccd-464c-8c0e-4d7d1e2520df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb38bdc-8e4d-48ca-ab0f-7af922b7f07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "X, y = tensorGenCla()\n",
    "\n",
    "# 计算一个完整的数据集中样本的个数 => 标量\n",
    "m = len(X)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b8951f-0a46-43f9-9bcf-b75dbdec5559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = list(range(m))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027c43d4-0d4a-4b20-82ed-7fe36f2e5c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[699,\n",
       " 1058,\n",
       " 239,\n",
       " 1404,\n",
       " 1236,\n",
       " 1115,\n",
       " 628,\n",
       " 482,\n",
       " 102,\n",
       " 149,\n",
       " 218,\n",
       " 195,\n",
       " 690,\n",
       " 296,\n",
       " 125,\n",
       " 596,\n",
       " 1013,\n",
       " 1469,\n",
       " 516,\n",
       " 756,\n",
       " 1191,\n",
       " 133,\n",
       " 1259,\n",
       " 910,\n",
       " 340,\n",
       " 778,\n",
       " 573,\n",
       " 462,\n",
       " 303,\n",
       " 619,\n",
       " 397,\n",
       " 1117,\n",
       " 962,\n",
       " 450,\n",
       " 499,\n",
       " 903,\n",
       " 67,\n",
       " 1460,\n",
       " 478,\n",
       " 585,\n",
       " 1332,\n",
       " 1134,\n",
       " 955,\n",
       " 1024,\n",
       " 849,\n",
       " 10,\n",
       " 1269,\n",
       " 266,\n",
       " 412,\n",
       " 696,\n",
       " 197,\n",
       " 558,\n",
       " 818,\n",
       " 733,\n",
       " 277,\n",
       " 1049,\n",
       " 64,\n",
       " 391,\n",
       " 1244,\n",
       " 822,\n",
       " 1421,\n",
       " 554,\n",
       " 458,\n",
       " 989,\n",
       " 483,\n",
       " 1074,\n",
       " 726,\n",
       " 225,\n",
       " 772,\n",
       " 59,\n",
       " 507,\n",
       " 1365,\n",
       " 531,\n",
       " 7,\n",
       " 686,\n",
       " 1445,\n",
       " 840,\n",
       " 472,\n",
       " 1400,\n",
       " 1420,\n",
       " 694,\n",
       " 611,\n",
       " 417,\n",
       " 1025,\n",
       " 1167,\n",
       " 119,\n",
       " 372,\n",
       " 988,\n",
       " 1021,\n",
       " 1201,\n",
       " 208,\n",
       " 1422,\n",
       " 730,\n",
       " 161,\n",
       " 390,\n",
       " 844,\n",
       " 687,\n",
       " 506,\n",
       " 575,\n",
       " 835,\n",
       " 238,\n",
       " 1363,\n",
       " 956,\n",
       " 1145,\n",
       " 378,\n",
       " 748,\n",
       " 574,\n",
       " 58,\n",
       " 539,\n",
       " 1161,\n",
       " 1077,\n",
       " 712,\n",
       " 465,\n",
       " 1386,\n",
       " 15,\n",
       " 202,\n",
       " 1001,\n",
       " 1051,\n",
       " 1256,\n",
       " 528,\n",
       " 786,\n",
       " 50,\n",
       " 1211,\n",
       " 746,\n",
       " 924,\n",
       " 680,\n",
       " 224,\n",
       " 375,\n",
       " 333,\n",
       " 718,\n",
       " 165,\n",
       " 490,\n",
       " 944,\n",
       " 759,\n",
       " 827,\n",
       " 1228,\n",
       " 230,\n",
       " 1409,\n",
       " 1113,\n",
       " 263,\n",
       " 345,\n",
       " 1307,\n",
       " 388,\n",
       " 1177,\n",
       " 958,\n",
       " 193,\n",
       " 677,\n",
       " 78,\n",
       " 1121,\n",
       " 821,\n",
       " 358,\n",
       " 1068,\n",
       " 1432,\n",
       " 1034,\n",
       " 861,\n",
       " 1262,\n",
       " 60,\n",
       " 1295,\n",
       " 547,\n",
       " 101,\n",
       " 946,\n",
       " 1317,\n",
       " 318,\n",
       " 298,\n",
       " 460,\n",
       " 1170,\n",
       " 288,\n",
       " 113,\n",
       " 1261,\n",
       " 454,\n",
       " 588,\n",
       " 425,\n",
       " 127,\n",
       " 98,\n",
       " 168,\n",
       " 586,\n",
       " 640,\n",
       " 6,\n",
       " 512,\n",
       " 395,\n",
       " 1251,\n",
       " 940,\n",
       " 613,\n",
       " 42,\n",
       " 791,\n",
       " 8,\n",
       " 1054,\n",
       " 709,\n",
       " 131,\n",
       " 1248,\n",
       " 108,\n",
       " 755,\n",
       " 1053,\n",
       " 557,\n",
       " 251,\n",
       " 578,\n",
       " 862,\n",
       " 68,\n",
       " 389,\n",
       " 663,\n",
       " 376,\n",
       " 645,\n",
       " 880,\n",
       " 371,\n",
       " 965,\n",
       " 1318,\n",
       " 1447,\n",
       " 1041,\n",
       " 1082,\n",
       " 933,\n",
       " 789,\n",
       " 463,\n",
       " 411,\n",
       " 757,\n",
       " 517,\n",
       " 307,\n",
       " 1016,\n",
       " 366,\n",
       " 1246,\n",
       " 713,\n",
       " 495,\n",
       " 256,\n",
       " 1171,\n",
       " 906,\n",
       " 287,\n",
       " 1128,\n",
       " 229,\n",
       " 154,\n",
       " 150,\n",
       " 116,\n",
       " 383,\n",
       " 265,\n",
       " 1116,\n",
       " 1415,\n",
       " 1467,\n",
       " 881,\n",
       " 381,\n",
       " 549,\n",
       " 553,\n",
       " 668,\n",
       " 141,\n",
       " 502,\n",
       " 732,\n",
       " 867,\n",
       " 56,\n",
       " 583,\n",
       " 846,\n",
       " 954,\n",
       " 63,\n",
       " 721,\n",
       " 398,\n",
       " 794,\n",
       " 1398,\n",
       " 1314,\n",
       " 798,\n",
       " 795,\n",
       " 607,\n",
       " 418,\n",
       " 945,\n",
       " 1126,\n",
       " 1079,\n",
       " 259,\n",
       " 523,\n",
       " 139,\n",
       " 1083,\n",
       " 28,\n",
       " 697,\n",
       " 1418,\n",
       " 192,\n",
       " 807,\n",
       " 385,\n",
       " 13,\n",
       " 1396,\n",
       " 1222,\n",
       " 267,\n",
       " 1478,\n",
       " 731,\n",
       " 875,\n",
       " 1391,\n",
       " 1313,\n",
       " 69,\n",
       " 1067,\n",
       " 740,\n",
       " 801,\n",
       " 181,\n",
       " 1424,\n",
       " 908,\n",
       " 1162,\n",
       " 1361,\n",
       " 1129,\n",
       " 93,\n",
       " 104,\n",
       " 1285,\n",
       " 964,\n",
       " 1114,\n",
       " 451,\n",
       " 143,\n",
       " 491,\n",
       " 1438,\n",
       " 419,\n",
       " 1150,\n",
       " 255,\n",
       " 812,\n",
       " 1431,\n",
       " 692,\n",
       " 114,\n",
       " 764,\n",
       " 571,\n",
       " 1003,\n",
       " 51,\n",
       " 155,\n",
       " 1348,\n",
       " 48,\n",
       " 1030,\n",
       " 1232,\n",
       " 1354,\n",
       " 354,\n",
       " 805,\n",
       " 630,\n",
       " 409,\n",
       " 1098,\n",
       " 885,\n",
       " 1078,\n",
       " 1373,\n",
       " 706,\n",
       " 1080,\n",
       " 1095,\n",
       " 565,\n",
       " 196,\n",
       " 301,\n",
       " 1308,\n",
       " 1188,\n",
       " 399,\n",
       " 438,\n",
       " 1446,\n",
       " 717,\n",
       " 352,\n",
       " 257,\n",
       " 1392,\n",
       " 685,\n",
       " 9,\n",
       " 856,\n",
       " 994,\n",
       " 1064,\n",
       " 40,\n",
       " 128,\n",
       " 1220,\n",
       " 1213,\n",
       " 350,\n",
       " 1439,\n",
       " 1061,\n",
       " 966,\n",
       " 743,\n",
       " 648,\n",
       " 1463,\n",
       " 1481,\n",
       " 901,\n",
       " 1094,\n",
       " 1190,\n",
       " 194,\n",
       " 304,\n",
       " 269,\n",
       " 1104,\n",
       " 1462,\n",
       " 552,\n",
       " 905,\n",
       " 492,\n",
       " 810,\n",
       " 1199,\n",
       " 587,\n",
       " 1470,\n",
       " 887,\n",
       " 925,\n",
       " 676,\n",
       " 405,\n",
       " 1369,\n",
       " 488,\n",
       " 625,\n",
       " 1038,\n",
       " 1144,\n",
       " 344,\n",
       " 770,\n",
       " 1180,\n",
       " 1350,\n",
       " 1272,\n",
       " 406,\n",
       " 855,\n",
       " 16,\n",
       " 1229,\n",
       " 1219,\n",
       " 306,\n",
       " 1298,\n",
       " 859,\n",
       " 1152,\n",
       " 1402,\n",
       " 1393,\n",
       " 414,\n",
       " 1423,\n",
       " 1473,\n",
       " 118,\n",
       " 91,\n",
       " 1482,\n",
       " 511,\n",
       " 162,\n",
       " 1374,\n",
       " 386,\n",
       " 1097,\n",
       " 1347,\n",
       " 515,\n",
       " 137,\n",
       " 455,\n",
       " 1027,\n",
       " 1081,\n",
       " 329,\n",
       " 1406,\n",
       " 869,\n",
       " 179,\n",
       " 671,\n",
       " 1221,\n",
       " 292,\n",
       " 1278,\n",
       " 1002,\n",
       " 998,\n",
       " 646,\n",
       " 1031,\n",
       " 349,\n",
       " 710,\n",
       " 593,\n",
       " 529,\n",
       " 1485,\n",
       " 985,\n",
       " 334,\n",
       " 582,\n",
       " 170,\n",
       " 848,\n",
       " 92,\n",
       " 1410,\n",
       " 1000,\n",
       " 898,\n",
       " 600,\n",
       " 1173,\n",
       " 17,\n",
       " 247,\n",
       " 719,\n",
       " 466,\n",
       " 1235,\n",
       " 1405,\n",
       " 36,\n",
       " 1017,\n",
       " 1140,\n",
       " 183,\n",
       " 189,\n",
       " 922,\n",
       " 377,\n",
       " 650,\n",
       " 1245,\n",
       " 1341,\n",
       " 1328,\n",
       " 175,\n",
       " 544,\n",
       " 305,\n",
       " 967,\n",
       " 220,\n",
       " 470,\n",
       " 1273,\n",
       " 1358,\n",
       " 1297,\n",
       " 1408,\n",
       " 485,\n",
       " 1429,\n",
       " 1282,\n",
       " 1040,\n",
       " 121,\n",
       " 1468,\n",
       " 1203,\n",
       " 248,\n",
       " 88,\n",
       " 1136,\n",
       " 83,\n",
       " 897,\n",
       " 1009,\n",
       " 579,\n",
       " 876,\n",
       " 551,\n",
       " 621,\n",
       " 1294,\n",
       " 1154,\n",
       " 152,\n",
       " 1255,\n",
       " 1387,\n",
       " 1309,\n",
       " 1381,\n",
       " 1448,\n",
       " 313,\n",
       " 72,\n",
       " 497,\n",
       " 1059,\n",
       " 250,\n",
       " 1434,\n",
       " 912,\n",
       " 223,\n",
       " 624,\n",
       " 1205,\n",
       " 1055,\n",
       " 21,\n",
       " 1435,\n",
       " 1182,\n",
       " 972,\n",
       " 186,\n",
       " 942,\n",
       " 429,\n",
       " 234,\n",
       " 316,\n",
       " 1087,\n",
       " 739,\n",
       " 904,\n",
       " 343,\n",
       " 656,\n",
       " 889,\n",
       " 751,\n",
       " 300,\n",
       " 481,\n",
       " 1389,\n",
       " 796,\n",
       " 936,\n",
       " 534,\n",
       " 440,\n",
       " 540,\n",
       " 1279,\n",
       " 1384,\n",
       " 513,\n",
       " 427,\n",
       " 1109,\n",
       " 1316,\n",
       " 1451,\n",
       " 960,\n",
       " 1495,\n",
       " 1339,\n",
       " 1455,\n",
       " 71,\n",
       " 1023,\n",
       " 325,\n",
       " 132,\n",
       " 190,\n",
       " 1271,\n",
       " 1147,\n",
       " 1141,\n",
       " 1106,\n",
       " 737,\n",
       " 609,\n",
       " 541,\n",
       " 453,\n",
       " 673,\n",
       " 363,\n",
       " 1238,\n",
       " 883,\n",
       " 1175,\n",
       " 200,\n",
       " 797,\n",
       " 520,\n",
       " 1280,\n",
       " 1124,\n",
       " 1214,\n",
       " 1479,\n",
       " 1155,\n",
       " 1253,\n",
       " 320,\n",
       " 1149,\n",
       " 85,\n",
       " 369,\n",
       " 842,\n",
       " 191,\n",
       " 1217,\n",
       " 34,\n",
       " 711,\n",
       " 899,\n",
       " 1224,\n",
       " 420,\n",
       " 1306,\n",
       " 806,\n",
       " 524,\n",
       " 736,\n",
       " 117,\n",
       " 1289,\n",
       " 1277,\n",
       " 1327,\n",
       " 464,\n",
       " 937,\n",
       " 1033,\n",
       " 501,\n",
       " 1165,\n",
       " 1326,\n",
       " 787,\n",
       " 1344,\n",
       " 1401,\n",
       " 570,\n",
       " 509,\n",
       " 1007,\n",
       " 1103,\n",
       " 1403,\n",
       " 1076,\n",
       " 992,\n",
       " 282,\n",
       " 347,\n",
       " 931,\n",
       " 84,\n",
       " 546,\n",
       " 184,\n",
       " 1015,\n",
       " 843,\n",
       " 957,\n",
       " 158,\n",
       " 177,\n",
       " 231,\n",
       " 39,\n",
       " 374,\n",
       " 799,\n",
       " 264,\n",
       " 728,\n",
       " 1179,\n",
       " 682,\n",
       " 1337,\n",
       " 444,\n",
       " 535,\n",
       " 22,\n",
       " 95,\n",
       " 753,\n",
       " 216,\n",
       " 934,\n",
       " 1290,\n",
       " 642,\n",
       " 331,\n",
       " 1008,\n",
       " 436,\n",
       " 335,\n",
       " 634,\n",
       " 817,\n",
       " 852,\n",
       " 448,\n",
       " 1291,\n",
       " 1305,\n",
       " 219,\n",
       " 496,\n",
       " 584,\n",
       " 1069,\n",
       " 902,\n",
       " 864,\n",
       " 198,\n",
       " 403,\n",
       " 433,\n",
       " 1264,\n",
       " 212,\n",
       " 1122,\n",
       " 362,\n",
       " 246,\n",
       " 785,\n",
       " 148,\n",
       " 701,\n",
       " 661,\n",
       " 446,\n",
       " 679,\n",
       " 1320,\n",
       " 1380,\n",
       " 120,\n",
       " 209,\n",
       " 961,\n",
       " 146,\n",
       " 1111,\n",
       " 1493,\n",
       " 870,\n",
       " 689,\n",
       " 1075,\n",
       " 1319,\n",
       " 1288,\n",
       " 1010,\n",
       " 974,\n",
       " 935,\n",
       " 254,\n",
       " 907,\n",
       " 813,\n",
       " 1020,\n",
       " 872,\n",
       " 172,\n",
       " 666,\n",
       " 971,\n",
       " 408,\n",
       " 380,\n",
       " 1353,\n",
       " 1105,\n",
       " 562,\n",
       " 360,\n",
       " 1057,\n",
       " 434,\n",
       " 758,\n",
       " 1156,\n",
       " 1452,\n",
       " 729,\n",
       " 639,\n",
       " 1187,\n",
       " 986,\n",
       " 80,\n",
       " 1100,\n",
       " 210,\n",
       " 387,\n",
       " 321,\n",
       " 232,\n",
       " 594,\n",
       " 708,\n",
       " 952,\n",
       " 90,\n",
       " 1005,\n",
       " 2,\n",
       " 53,\n",
       " 1378,\n",
       " 947,\n",
       " 564,\n",
       " 29,\n",
       " 602,\n",
       " 1066,\n",
       " 422,\n",
       " 975,\n",
       " 156,\n",
       " 1413,\n",
       " 761,\n",
       " 508,\n",
       " 1377,\n",
       " 543,\n",
       " 1119,\n",
       " 693,\n",
       " 272,\n",
       " 480,\n",
       " 983,\n",
       " 228,\n",
       " 1368,\n",
       " 1260,\n",
       " 1315,\n",
       " 688,\n",
       " 129,\n",
       " 233,\n",
       " 1487,\n",
       " 110,\n",
       " 590,\n",
       " 368,\n",
       " 281,\n",
       " 107,\n",
       " 379,\n",
       " 939,\n",
       " 829,\n",
       " 911,\n",
       " 819,\n",
       " 77,\n",
       " 768,\n",
       " 477,\n",
       " 793,\n",
       " 351,\n",
       " 1202,\n",
       " 479,\n",
       " 99,\n",
       " 43,\n",
       " 684,\n",
       " 747,\n",
       " 1425,\n",
       " 33,\n",
       " 293,\n",
       " 227,\n",
       " 1263,\n",
       " 545,\n",
       " 527,\n",
       " 217,\n",
       " 1197,\n",
       " 407,\n",
       " 1475,\n",
       " 1419,\n",
       " 948,\n",
       " 691,\n",
       " 1349,\n",
       " 522,\n",
       " 589,\n",
       " 241,\n",
       " 55,\n",
       " 1028,\n",
       " 73,\n",
       " 536,\n",
       " 550,\n",
       " 1172,\n",
       " 623,\n",
       " 926,\n",
       " 295,\n",
       " 1046,\n",
       " 1037,\n",
       " 1281,\n",
       " 342,\n",
       " 357,\n",
       " 124,\n",
       " 1184,\n",
       " 338,\n",
       " 1383,\n",
       " 1330,\n",
       " 1086,\n",
       " 830,\n",
       " 555,\n",
       " 38,\n",
       " 977,\n",
       " 276,\n",
       " 1372,\n",
       " 886,\n",
       " 1242,\n",
       " 11,\n",
       " 1225,\n",
       " 832,\n",
       " 1287,\n",
       " 1335,\n",
       " 54,\n",
       " 510,\n",
       " 1441,\n",
       " 987,\n",
       " 1159,\n",
       " 410,\n",
       " 1428,\n",
       " 681,\n",
       " 236,\n",
       " 1329,\n",
       " 206,\n",
       " 18,\n",
       " 723,\n",
       " 662,\n",
       " 982,\n",
       " 943,\n",
       " 245,\n",
       " 820,\n",
       " 996,\n",
       " 1465,\n",
       " 683,\n",
       " 337,\n",
       " 914,\n",
       " 258,\n",
       " 1160,\n",
       " 160,\n",
       " 367,\n",
       " 1014,\n",
       " 891,\n",
       " 336,\n",
       " 1056,\n",
       " 1491,\n",
       " 66,\n",
       " 97,\n",
       " 665,\n",
       " 828,\n",
       " 35,\n",
       " 1266,\n",
       " 769,\n",
       " 638,\n",
       " 330,\n",
       " 134,\n",
       " 459,\n",
       " 863,\n",
       " 735,\n",
       " 1426,\n",
       " 622,\n",
       " 1118,\n",
       " 1300,\n",
       " 222,\n",
       " 297,\n",
       " 1072,\n",
       " 790,\n",
       " 651,\n",
       " 702,\n",
       " 741,\n",
       " 568,\n",
       " 1437,\n",
       " 126,\n",
       " 734,\n",
       " 598,\n",
       " 1042,\n",
       " 290,\n",
       " 106,\n",
       " 767,\n",
       " 991,\n",
       " 604,\n",
       " 4,\n",
       " 1360,\n",
       " 505,\n",
       " 341,\n",
       " 474,\n",
       " 1274,\n",
       " 167,\n",
       " 1496,\n",
       " 1321,\n",
       " 1070,\n",
       " 1185,\n",
       " 714,\n",
       " 963,\n",
       " 1362,\n",
       " 929,\n",
       " 1258,\n",
       " 1483,\n",
       " 823,\n",
       " 1352,\n",
       " 858,\n",
       " 302,\n",
       " 643,\n",
       " 715,\n",
       " 1223,\n",
       " 1450,\n",
       " 631,\n",
       " 893,\n",
       " 909,\n",
       " 1436,\n",
       " 970,\n",
       " 874,\n",
       " 884,\n",
       " 777,\n",
       " 1043,\n",
       " 1356,\n",
       " 1204,\n",
       " 1440,\n",
       " 781,\n",
       " 142,\n",
       " 1397,\n",
       " 896,\n",
       " 211,\n",
       " 930,\n",
       " 1407,\n",
       " 800,\n",
       " 473,\n",
       " 1399,\n",
       " 824,\n",
       " 1209,\n",
       " 659,\n",
       " 1390,\n",
       " 20,\n",
       " 1164,\n",
       " 851,\n",
       " 432,\n",
       " 599,\n",
       " 486,\n",
       " 566,\n",
       " 608,\n",
       " 503,\n",
       " 605,\n",
       " 1084,\n",
       " 649,\n",
       " 745,\n",
       " 567,\n",
       " 980,\n",
       " 754,\n",
       " 1123,\n",
       " 674,\n",
       " 1370,\n",
       " 752,\n",
       " 837,\n",
       " 1138,\n",
       " 140,\n",
       " 700,\n",
       " 159,\n",
       " 1301,\n",
       " 969,\n",
       " 144,\n",
       " 310,\n",
       " 1045,\n",
       " 1176,\n",
       " 868,\n",
       " 1286,\n",
       " 1,\n",
       " 413,\n",
       " 400,\n",
       " 1474,\n",
       " 526,\n",
       " 530,\n",
       " 1193,\n",
       " 443,\n",
       " 1011,\n",
       " 606,\n",
       " 14,\n",
       " 941,\n",
       " 725,\n",
       " 1216,\n",
       " 1299,\n",
       " 722,\n",
       " 1158,\n",
       " 704,\n",
       " 654,\n",
       " 1243,\n",
       " 873,\n",
       " 569,\n",
       " 176,\n",
       " 595,\n",
       " 592,\n",
       " 919,\n",
       " 469,\n",
       " 187,\n",
       " 514,\n",
       " 921,\n",
       " 1382,\n",
       " 324,\n",
       " 308,\n",
       " 1060,\n",
       " 261,\n",
       " 249,\n",
       " 871,\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(indices)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d93379e-5ac6-4838-b5f8-e5e18d9bd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, rate=0.7):\n",
    "    \"\"\"将一个完整的数据集划分为训练数据集和测试数据集, 数据集包括特征变量和标签\n",
    "    @param X: 特征变量\n",
    "    @param y: 标签\n",
    "    @param rate: 训练数据集占完整数据集的比例\n",
    "    \n",
    "    @return X_train, X_test, y_train, y_test: 训练数据集和测试数据集\n",
    "    \"\"\"\n",
    "    # 1.计算一个完整的数据集中样本的个数 => 标量\n",
    "    m = len(X)\n",
    "    # 2.在计算机的内存中一次性存储1～500总共500个标量 => 存储在数据结构列表中\n",
    "    indices = list(range(m))\n",
    "    # 3.原地in-place打乱样本的索引顺序\n",
    "    random.shuffle(indices)\n",
    "    # 4.计算训练数据集中的样本的个数 => 标量\n",
    "    m_train = int(m * rate)  # 报错: TypeError: slice indices must be integers\n",
    "    # 5.分别获取训练数据集中样本的索引和测试数据集中样本的索引\n",
    "    indices_train = torch.tensor(indices[:m_train], dtype=torch.int32)\n",
    "    indices_test = torch.tensor(indices[m_train:], dtype=torch.int32)\n",
    "    # 6.在计算机的内存中一次性存储训练数据集中的特征变量和标签\n",
    "    X_train = X[indices_train]\n",
    "    y_train = y[indices_train]\n",
    "    # 7.在计算机的内存中一次性存储测试数据集中的特征变量和标签\n",
    "    X_test = X[indices_test]\n",
    "    y_test = y[indices_test]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3761b95b-2eee-496e-a6ff-988c14111cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在计算机的内存中一次性存储多个数. 从0-9\n",
    "f = torch.arange(start=0, end=10, step=1)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e1294a-771a-4e90-987c-a2b48f80826e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在计算机的内存中一次性存储多个数. 从1-10\n",
    "l = torch.arange(start=1, end=11, step=1)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0085ee03-d5bc-42c5-b74c-9fc5baab034c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 0, 4, 8, 5, 1, 9]),\n",
       " tensor([2, 6, 7]),\n",
       " tensor([ 4,  1,  5,  9,  6,  2, 10]),\n",
       " tensor([3, 7, 8]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(X=f, y=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f222261-1098-4b0d-8976-90b2ef467df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11e20c550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "X, y = tensorGenReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a249675-bd8a-4351-8f7b-dabde0f60ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8616,  0.9035,  1.0000],\n",
       "        [ 1.3395,  1.2005,  1.0000],\n",
       "        [ 1.0070,  0.2379,  1.0000],\n",
       "        ...,\n",
       "        [-0.0973, -0.4635,  1.0000],\n",
       "        [ 0.1802, -0.3851,  1.0000],\n",
       "        [-0.2370, -0.9159,  1.0000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cbacdf7-ac7c-4fe0-95c0-63c29bf7298e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11e20c550>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 加载原始数据集\n",
    "X, y = tensorGenReg()\n",
    "\n",
    "# 将完整的数据集划分为训练数据集和测试数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2b73bce-1157-4d15-baab-dd5e2d71a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11e20c550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 搭建深度神经网络模型的架构\n",
    "net = linear_regression\n",
    "\n",
    "# 实例化模型, 初始化模型的参数\n",
    "w = torch.zeros(size=(X.shape[1], 1), requires_grad=True)\n",
    "\n",
    "# 选择合适的损失函数\n",
    "criterion = squared_loss\n",
    "\n",
    "# 选择合适的优化器\n",
    "eta = 0.03\n",
    "\n",
    "# 搭建深度神经网络模型的训练流程\n",
    "# =====> 数据部分:\n",
    "# 1.将一个完整的数据集学习多遍, 设置学习的遍数 => 标量\n",
    "n_epochs = 5\n",
    "# 2.每一遍将一个完整的数据集按照一定的大小划分为若干个互不相交的子数据集, 设置子数据集的大小 => 标量\n",
    "batch_size = 10\n",
    "\n",
    "# =====> 模型训练部分:\n",
    "for i_epoch in range(n_epochs):  # 0 1 2 3 4 总共五个数\n",
    "    # print(i_epoch)\n",
    "    for (i_X, i_y) in split_dataset(batch_size=batch_size, X=X_train, y=y_train):\n",
    "        # 前向传播, 计算当前模型在当前参数设置下的预测输出标记\n",
    "        z_hat = net(i_X, w)\n",
    "        # 计算损失, 计算预测输出标记和真实标签之间的误差. 构建完整的计算图\n",
    "        loss = criterion(z_hat, i_y)\n",
    "        # 反向传播, 计算当前模型的所有参数在当前参数取值下的偏导函数信息\n",
    "        loss.backward()\n",
    "        # 参数更新, 优化器借助反向传播提供的信息, 按照一定的规则更新模型的所有参数的取值\n",
    "        stochastic_gradient_descent(params=w, lr=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920fb272-6b21-4369-84ed-b74a220bcdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9997],\n",
       "        [-1.0004],\n",
       "        [ 1.0005]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取训练完成的模型的参数\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "416c9952-7e27-4aa8-bef5-71532341b703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.3047e-05, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算训练完成的模型在训练数据集上的损失函数的取值\n",
    "loss_train = criterion(net(X_train, w), y_train)\n",
    "loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e05f0f6-d1e7-44f3-a011-a7fd214328d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算训练完成的模型在测试数据集上的损失函数的取值\n",
    "loss_test = criterion(net(X_test, w), y_test)\n",
    "loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899f7190-b136-49d0-9baf-7ae3ff5ea838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模块中的函数\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3abd5154-6268-4c12-a6e8-6cd809d2b567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在计算机的内存中一次性存储多个数值. e.g. 从0-11  选择数据结构张量 => 二维张量, 形状是四行三列\n",
    "t = torch.arange(start=0, end=12, step=1).reshape(4, 3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a54c3e-e51e-4c29-beeb-9de7e3e1dd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.Subset at 0x121748790>,\n",
       " <torch.utils.data.dataset.Subset at 0x121ed42e0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_split(dataset=t, lengths=[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c9e4bab-3686-4535-808c-e045c6f22df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_split(dataset=t, lengths=[2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b3c1f75-ff02-4129-ac09-37c717d70cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.Subset"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f59aaa6-e5fc-4a8a-8dda-80cf0c79556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 5])\n",
      "tensor([0, 1, 2])\n",
      "tensor([ 9, 10, 11])\n",
      "tensor([6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "for train, test in random_split(dataset=t, lengths=[2, 2]):\n",
    "    print(train)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93b3291a-2035-41d8-9653-de4659b1c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模块中的类\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c90d6c8f-cc2d-4ba5-9282-c01781064262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "X, y = tensorGenReg(bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d46e1b2-91ea-485d-b829-1dc7392035e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2462, -0.3578, -0.1369],\n",
       "        [ 0.9560,  1.0662, -1.0513],\n",
       "        [-1.7488, -0.8720,  0.5953],\n",
       "        ...,\n",
       "        [ 1.3293,  2.3669, -0.5442],\n",
       "        [ 1.0400, -1.4623,  0.0896],\n",
       "        [ 0.9643, -0.8364,  1.2889]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f00a1539-b098-4dcd-9a92-e2b6b98bc72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x1219b8640>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用TensorDataset是因为想将特征变量和标签打包放在一个元组中\n",
    "dataset = TensorDataset(X, y)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95604642-ea7e-4f45-800e-b2fba5226568",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TensorDataset类的paramter只能接受多个tensor数据类型的数据\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/computational_biology/anaconda/anaconda3/envs/DL/lib/python3.10/site-packages/torch/utils/data/dataset.py:202\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "File \u001b[0;32m~/Documents/computational_biology/anaconda/anaconda3/envs/DL/lib/python3.10/site-packages/torch/utils/data/dataset.py:202\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# TensorDataset类的paramter只能接受多个tensor数据类型的数据\n",
    "TensorDataset([1, 2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "309baa14-c693-4457-9aa1-4847a763a39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Dataset wrapping tensors.\n",
       "\n",
       "Each sample will be retrieved by indexing tensors along the first dimension.\n",
       "\n",
       "Args:\n",
       "    *tensors (Tensor): tensors that have the same size of the first dimension.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Documents/computational_biology/anaconda/anaconda3/envs/DL/lib/python3.10/site-packages/torch/utils/data/dataset.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TensorDataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cea799e9-529a-4462-93cc-872e19b4bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载Scikit-learn项目的内置数据集\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "dataset = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e199068b-31e6-4e2e-8474-fde7b5c3d38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据集中的特征矩阵\n",
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5833aac-1b43-40ce-8852-6f546da131a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据集中的标签\n",
    "dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af855ae6-4480-4512-912c-dc22500542bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算数据集中样本的个数 => 标量\n",
    "m = len(dataset.data)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b89d08eb-072b-406f-9a0b-21605b52e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过非PyTorch模块加载数据集. e.g. 通过Scikit-learn模块\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "ml_dataset = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "525c993f-3ca5-4cb0-bcda-7930f6fab6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将通过非PyTorch模块加载的数据集 转换为 PyTorch模块在搭建深度神经网络模型训练过程时使用的数据集\n",
    "class LBCDataset(Dataset):\n",
    "    # 构造器 + 类/成员属性\n",
    "    # => 子类的对象调用父类的构造器\n",
    "    def __init__(self, dataset):\n",
    "        self.X = dataset.data\n",
    "        self.y = dataset.target\n",
    "        self.m = len(dataset.data)\n",
    "        \n",
    "    # 方法\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index, :], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3a8f8f8-084c-41d0-9d7b-8a0b9c3e4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_dataset = LBCDataset(dataset=ml_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bed5b54f-d2b8-41ec-b86e-b2a1b7a9358a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 深度机器学习中的数据集\n",
    "dl_dataset.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ab24552-03c9-4f48-a3fa-d687fc95bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c75463f4-9b2f-4749-9fc3-195f2d6fc7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6004e4a-c2e7-4739-8547-e02a4c67970e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]),\n",
       " 0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset.__getitem__(index=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d746466b-65d2-40f1-a068-898423a1d287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]),\n",
       " 0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86700ca8-0207-4b51-be03-e0a658fa1423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "       1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "       4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "       2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "       1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset.X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "707891f6-9a3d-4daa-87aa-3bd75514739c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset.y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a6c3566-4829-4455-8228-6a2d16a755e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2fd07c07-9ec7-441b-a35b-b59d72dc4037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 有一个完整的数据集, 计算数据集中样本的个数 => 标量\n",
    "m = len(dl_dataset)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f883e3dc-05bf-4d7f-ad46-6d6f0b9b1bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果按照训练数据集样本数占总样本数的70%, 剩余30%为测试数据集样本数\n",
    "rate = 0.7\n",
    "# 1.计算训练数据集中的样本数\n",
    "m_train = int(m * rate)\n",
    "m_train\n",
    "# 2.计算测试数据集中的样本数. 训练数据集中的样本数+测试数据集中的样本数=完整数据集中的样本数\n",
    "m_test = m - m_train\n",
    "m_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79679056-250c-42f6-ae3e-ea1d8a94aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_dataset_train, dl_dataset_test = random_split(dataset=dl_dataset, lengths=[m_train, m_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13b9a8bb-2fa9-46ec-9a54-61170b9c96c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x11e20c550\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Randomly split a dataset into non-overlapping new datasets of given lengths.\n",
       "\n",
       "If a list of fractions that sum up to 1 is given,\n",
       "the lengths will be computed automatically as\n",
       "floor(frac * len(dataset)) for each fraction provided.\n",
       "\n",
       "After computing the lengths, if there are any remainders, 1 count will be\n",
       "distributed in round-robin fashion to the lengths\n",
       "until there are no remainders left.\n",
       "\n",
       "Optionally fix the generator for reproducible results, e.g.:\n",
       "\n",
       "Example:\n",
       "    >>> # xdoctest: +SKIP\n",
       "    >>> generator1 = torch.Generator().manual_seed(42)\n",
       "    >>> generator2 = torch.Generator().manual_seed(42)\n",
       "    >>> random_split(range(10), [3, 7], generator=generator1)\n",
       "    >>> random_split(range(30), [0.3, 0.3, 0.4], generator=generator2)\n",
       "\n",
       "Args:\n",
       "    dataset (Dataset): Dataset to be split\n",
       "    lengths (sequence): lengths or fractions of splits to be produced\n",
       "    generator (Generator): Generator used for the random permutation.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/computational_biology/anaconda/anaconda3/envs/DL/lib/python3.10/site-packages/torch/utils/data/dataset.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39a6e02a-ef39-4dc4-a446-31f1124174ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LBCDataset at 0x129b839a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset_train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "828206a7-2692-48df-bd4c-fdbd55db136f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[413,\n",
       " 105,\n",
       " 235,\n",
       " 176,\n",
       " 449,\n",
       " 393,\n",
       " 104,\n",
       " 230,\n",
       " 383,\n",
       " 192,\n",
       " 44,\n",
       " 43,\n",
       " 97,\n",
       " 63,\n",
       " 48,\n",
       " 7,\n",
       " 421,\n",
       " 258,\n",
       " 164,\n",
       " 227,\n",
       " 274,\n",
       " 271,\n",
       " 328,\n",
       " 300,\n",
       " 507,\n",
       " 160,\n",
       " 234,\n",
       " 145,\n",
       " 273,\n",
       " 409,\n",
       " 322,\n",
       " 245,\n",
       " 499,\n",
       " 319,\n",
       " 149,\n",
       " 251,\n",
       " 332,\n",
       " 214,\n",
       " 500,\n",
       " 491,\n",
       " 401,\n",
       " 287,\n",
       " 386,\n",
       " 270,\n",
       " 151,\n",
       " 228,\n",
       " 16,\n",
       " 407,\n",
       " 361,\n",
       " 505,\n",
       " 496,\n",
       " 343,\n",
       " 94,\n",
       " 476,\n",
       " 396,\n",
       " 439,\n",
       " 15,\n",
       " 454,\n",
       " 461,\n",
       " 111,\n",
       " 47,\n",
       " 188,\n",
       " 294,\n",
       " 538,\n",
       " 252,\n",
       " 399,\n",
       " 291,\n",
       " 283,\n",
       " 114,\n",
       " 150,\n",
       " 357,\n",
       " 560,\n",
       " 46,\n",
       " 66,\n",
       " 297,\n",
       " 548,\n",
       " 200,\n",
       " 410,\n",
       " 285,\n",
       " 502,\n",
       " 329,\n",
       " 381,\n",
       " 464,\n",
       " 62,\n",
       " 136,\n",
       " 241,\n",
       " 545,\n",
       " 8,\n",
       " 309,\n",
       " 45,\n",
       " 205,\n",
       " 430,\n",
       " 471,\n",
       " 275,\n",
       " 369,\n",
       " 355,\n",
       " 312,\n",
       " 327,\n",
       " 103,\n",
       " 194,\n",
       " 148,\n",
       " 497,\n",
       " 253,\n",
       " 390,\n",
       " 85,\n",
       " 165,\n",
       " 244,\n",
       " 444,\n",
       " 565,\n",
       " 451,\n",
       " 125,\n",
       " 354,\n",
       " 462,\n",
       " 36,\n",
       " 23,\n",
       " 384,\n",
       " 299,\n",
       " 232,\n",
       " 350,\n",
       " 561,\n",
       " 147,\n",
       " 184,\n",
       " 338,\n",
       " 1,\n",
       " 517,\n",
       " 514,\n",
       " 42,\n",
       " 187,\n",
       " 59,\n",
       " 108,\n",
       " 448,\n",
       " 254,\n",
       " 304,\n",
       " 286,\n",
       " 50,\n",
       " 537,\n",
       " 478,\n",
       " 412,\n",
       " 73,\n",
       " 387,\n",
       " 100,\n",
       " 406,\n",
       " 223,\n",
       " 246,\n",
       " 177,\n",
       " 453,\n",
       " 318,\n",
       " 154,\n",
       " 219,\n",
       " 415,\n",
       " 14,\n",
       " 236,\n",
       " 33,\n",
       " 482,\n",
       " 78,\n",
       " 222,\n",
       " 190,\n",
       " 442,\n",
       " 368,\n",
       " 306,\n",
       " 434,\n",
       " 34,\n",
       " 534,\n",
       " 563,\n",
       " 84,\n",
       " 170,\n",
       " 175,\n",
       " 542,\n",
       " 19,\n",
       " 109,\n",
       " 310,\n",
       " 556,\n",
       " 209,\n",
       " 349,\n",
       " 81,\n",
       " 551,\n",
       " 377,\n",
       " 469,\n",
       " 101,\n",
       " 298,\n",
       " 95,\n",
       " 566,\n",
       " 405,\n",
       " 132,\n",
       " 141,\n",
       " 431,\n",
       " 3,\n",
       " 88,\n",
       " 418,\n",
       " 558,\n",
       " 521,\n",
       " 256,\n",
       " 65,\n",
       " 225,\n",
       " 416,\n",
       " 12,\n",
       " 524,\n",
       " 28,\n",
       " 385,\n",
       " 494,\n",
       " 262,\n",
       " 115,\n",
       " 60,\n",
       " 69,\n",
       " 555,\n",
       " 345,\n",
       " 508,\n",
       " 495,\n",
       " 83,\n",
       " 231,\n",
       " 80,\n",
       " 261,\n",
       " 532,\n",
       " 143,\n",
       " 54,\n",
       " 376,\n",
       " 93,\n",
       " 41,\n",
       " 131,\n",
       " 128,\n",
       " 199,\n",
       " 268,\n",
       " 169,\n",
       " 21,\n",
       " 419,\n",
       " 468,\n",
       " 533,\n",
       " 29,\n",
       " 22,\n",
       " 436,\n",
       " 204,\n",
       " 240,\n",
       " 388,\n",
       " 277,\n",
       " 341,\n",
       " 512,\n",
       " 212,\n",
       " 260,\n",
       " 174,\n",
       " 168,\n",
       " 425,\n",
       " 181,\n",
       " 53,\n",
       " 189,\n",
       " 17,\n",
       " 290,\n",
       " 127,\n",
       " 40,\n",
       " 365,\n",
       " 279,\n",
       " 186,\n",
       " 146,\n",
       " 308,\n",
       " 98,\n",
       " 112,\n",
       " 307,\n",
       " 197,\n",
       " 118,\n",
       " 389,\n",
       " 249,\n",
       " 242,\n",
       " 353,\n",
       " 428,\n",
       " 182,\n",
       " 458,\n",
       " 152,\n",
       " 121,\n",
       " 490,\n",
       " 172,\n",
       " 550,\n",
       " 250,\n",
       " 446,\n",
       " 371,\n",
       " 90,\n",
       " 171,\n",
       " 25,\n",
       " 9,\n",
       " 166,\n",
       " 539,\n",
       " 68,\n",
       " 525,\n",
       " 74,\n",
       " 527,\n",
       " 317,\n",
       " 158,\n",
       " 247,\n",
       " 340,\n",
       " 124,\n",
       " 326,\n",
       " 185,\n",
       " 323,\n",
       " 75,\n",
       " 196,\n",
       " 348,\n",
       " 403,\n",
       " 358,\n",
       " 183,\n",
       " 229,\n",
       " 374,\n",
       " 484,\n",
       " 293,\n",
       " 475,\n",
       " 130,\n",
       " 429,\n",
       " 303,\n",
       " 535,\n",
       " 515,\n",
       " 263,\n",
       " 513,\n",
       " 346,\n",
       " 301,\n",
       " 359,\n",
       " 423,\n",
       " 191,\n",
       " 37,\n",
       " 288,\n",
       " 408,\n",
       " 102,\n",
       " 302,\n",
       " 373,\n",
       " 334,\n",
       " 87,\n",
       " 511,\n",
       " 438,\n",
       " 162,\n",
       " 380,\n",
       " 473,\n",
       " 57,\n",
       " 55,\n",
       " 466,\n",
       " 356,\n",
       " 31,\n",
       " 91,\n",
       " 106,\n",
       " 546,\n",
       " 96,\n",
       " 110,\n",
       " 498,\n",
       " 443,\n",
       " 178,\n",
       " 311,\n",
       " 239,\n",
       " 77,\n",
       " 289,\n",
       " 485,\n",
       " 39,\n",
       " 544,\n",
       " 397,\n",
       " 134,\n",
       " 296,\n",
       " 562,\n",
       " 49,\n",
       " 180,\n",
       " 159,\n",
       " 38,\n",
       " 167,\n",
       " 414,\n",
       " 269,\n",
       " 266,\n",
       " 391,\n",
       " 474,\n",
       " 137,\n",
       " 520,\n",
       " 140,\n",
       " 488,\n",
       " 557,\n",
       " 523,\n",
       " 155,\n",
       " 501,\n",
       " 422,\n",
       " 554,\n",
       " 213,\n",
       " 342,\n",
       " 280,\n",
       " 161,\n",
       " 173,\n",
       " 447,\n",
       " 487,\n",
       " 207,\n",
       " 315,\n",
       " 281,\n",
       " 26,\n",
       " 259,\n",
       " 119,\n",
       " 567,\n",
       " 179,\n",
       " 417,\n",
       " 459,\n",
       " 492,\n",
       " 133,\n",
       " 480,\n",
       " 568,\n",
       " 107,\n",
       " 282,\n",
       " 472,\n",
       " 201,\n",
       " 465,\n",
       " 479]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset_train.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d27e6180-fe1d-47b5-93bf-8c88f9eca615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_dataset_train.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed9839a0-1b5f-4d25-be77-dedc33ee35c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset_train.dataset == dl_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "caadcbc2-963a-4f9a-93d3-321d46729ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.499e+01, 2.211e+01, 9.753e+01, 6.937e+02, 8.515e-02, 1.025e-01,\n",
      "       6.859e-02, 3.876e-02, 1.944e-01, 5.913e-02, 3.186e-01, 1.336e+00,\n",
      "       2.310e+00, 2.851e+01, 4.449e-03, 2.808e-02, 3.312e-02, 1.196e-02,\n",
      "       1.906e-02, 4.015e-03, 1.676e+01, 3.155e+01, 1.102e+02, 8.671e+02,\n",
      "       1.077e-01, 3.345e-01, 3.114e-01, 1.308e-01, 3.163e-01, 9.251e-02]), 1)\n"
     ]
    }
   ],
   "source": [
    "for sample in dl_dataset_train:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8f4bf97-7829-4bfa-aa6d-54a40830025e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
      "       3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
      "       8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
      "       3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
      "       1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01]), 0)\n"
     ]
    }
   ],
   "source": [
    "for sample in dl_dataset_train.dataset:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0f3ad86-d178-4b33-b91c-3a4e9eab93ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n"
     ]
    }
   ],
   "source": [
    "for index in dl_dataset_train.indices:\n",
    "    print(index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f2da7c3-43b1-4f6b-9aa2-903e340b28bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
      "       3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
      "       8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
      "       3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
      "       1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01]), 0)\n"
     ]
    }
   ],
   "source": [
    "for sample in dl_dataset:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3e97399-a4a9-4e08-9fad-05892151d82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.328e+01, 1.372e+01, 8.579e+01, 5.418e+02, 8.363e-02, 8.575e-02,\n",
       "        5.077e-02, 2.864e-02, 1.617e-01, 5.594e-02, 1.833e-01, 5.308e-01,\n",
       "        1.592e+00, 1.526e+01, 4.271e-03, 2.073e-02, 2.828e-02, 8.468e-03,\n",
       "        1.461e-02, 2.613e-03, 1.424e+01, 1.737e+01, 9.659e+01, 6.237e+02,\n",
       "        1.166e-01, 2.685e-01, 2.866e-01, 9.173e-02, 2.736e-01, 7.320e-02]),\n",
       " 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset.__getitem__(384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc5a73f0-315e-4d80-a34a-c33a8ac3defb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.499e+01, 2.211e+01, 9.753e+01, ..., 1.308e-01, 3.163e-01,\n",
       "         9.251e-02],\n",
       "        [1.311e+01, 1.556e+01, 8.721e+01, ..., 1.986e-01, 3.147e-01,\n",
       "         1.405e-01],\n",
       "        [1.403e+01, 2.125e+01, 8.979e+01, ..., 7.963e-02, 2.226e-01,\n",
       "         7.617e-02],\n",
       "        ...,\n",
       "        [1.754e+01, 1.932e+01, 1.151e+02, ..., 1.939e-01, 2.928e-01,\n",
       "         7.867e-02],\n",
       "        [1.324e+01, 2.013e+01, 8.687e+01, ..., 1.357e-01, 2.845e-01,\n",
       "         1.249e-01],\n",
       "        [1.625e+01, 1.951e+01, 1.098e+02, ..., 1.775e-01, 3.318e-01,\n",
       "         9.136e-02]]),\n",
       " array([1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "        1, 0]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_dataset[dl_dataset_train.indices]  # 获取所有的训练数据集中的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68b4e105-de09-414c-911f-4a05b55a9dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_dataset_train.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fd1a5f1-0bfd-4cfa-aba5-611fd4f9dc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mT_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworker_init_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmultiprocessing_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprefetch_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpersistent_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
       "\n",
       "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
       "iterable-style datasets with single- or multi-process loading, customizing\n",
       "loading order and optional automatic batching (collation) and memory pinning.\n",
       "\n",
       "See :py:mod:`torch.utils.data` documentation page for more details.\n",
       "\n",
       "Args:\n",
       "    dataset (Dataset): dataset from which to load the data.\n",
       "    batch_size (int, optional): how many samples per batch to load\n",
       "        (default: ``1``).\n",
       "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
       "        at every epoch (default: ``False``).\n",
       "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
       "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
       "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
       "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
       "        returns a batch of indices at a time. Mutually exclusive with\n",
       "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
       "        and :attr:`drop_last`.\n",
       "    num_workers (int, optional): how many subprocesses to use for data\n",
       "        loading. ``0`` means that the data will be loaded in the main process.\n",
       "        (default: ``0``)\n",
       "    collate_fn (Callable, optional): merges a list of samples to form a\n",
       "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
       "        map-style dataset.\n",
       "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
       "        into device/CUDA pinned memory before returning them.  If your data elements\n",
       "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
       "        see the example below.\n",
       "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
       "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
       "        the size of dataset is not divisible by the batch size, then the last batch\n",
       "        will be smaller. (default: ``False``)\n",
       "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
       "        from workers. Should always be non-negative. (default: ``0``)\n",
       "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
       "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
       "        input, after seeding and before data loading. (default: ``None``)\n",
       "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
       "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
       "        be used. (default: ``None``)\n",
       "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
       "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
       "        ``base_seed`` for workers. (default: ``None``)\n",
       "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
       "        in advance by each worker. ``2`` means there will be a total of\n",
       "        2 * num_workers batches prefetched across all workers. (default value depends\n",
       "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
       "        Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
       "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
       "        the worker processes after a dataset has been consumed once. This allows to\n",
       "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
       "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
       "        ``True``.\n",
       "\n",
       "\n",
       ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
       "             cannot be an unpicklable object, e.g., a lambda function. See\n",
       "             :ref:`multiprocessing-best-practices` on more details related\n",
       "             to multiprocessing in PyTorch.\n",
       "\n",
       ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
       "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
       "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
       "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
       "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
       "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
       "             loading to avoid duplicate data.\n",
       "\n",
       "             However, if sharding results in multiple workers having incomplete last batches,\n",
       "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
       "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
       "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
       "             cases in general.\n",
       "\n",
       "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
       "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
       "             `Multi-process data loading`_.\n",
       "\n",
       ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
       "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
       "\n",
       ".. _multiprocessing context:\n",
       "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Documents/computational_biology/anaconda/anaconda3/envs/DL/lib/python3.10/site-packages/torch/utils/data/dataloader.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4f69f50-c280-44c7-800d-dd39052a1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将一个完整的训练数据集按照指定的大小划分为若干个互不相交的子数据集\n",
    "batched_dl_dataset_train = DataLoader(dataset=dl_dataset_train, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1abc4cab-9153-470e-98da-2be6ed2c2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将一个完整的测试数据集按照指定的大小划分为若干个互不相交的子数据集\n",
    "batched_dl_dataset_test = DataLoader(dataset=dl_dataset_test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09b50482-9f01-491c-83bb-f26023ca4393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.499e+01, 2.211e+01, 9.753e+01, 6.937e+02, 8.515e-02, 1.025e-01,\n",
      "       6.859e-02, 3.876e-02, 1.944e-01, 5.913e-02, 3.186e-01, 1.336e+00,\n",
      "       2.310e+00, 2.851e+01, 4.449e-03, 2.808e-02, 3.312e-02, 1.196e-02,\n",
      "       1.906e-02, 4.015e-03, 1.676e+01, 3.155e+01, 1.102e+02, 8.671e+02,\n",
      "       1.077e-01, 3.345e-01, 3.114e-01, 1.308e-01, 3.163e-01, 9.251e-02]), 1)\n"
     ]
    }
   ],
   "source": [
    "for sample in dl_dataset_train:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb492888-774d-4e44-b62b-ffb0ef489e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dl_dataset_test.dataset == dl_dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eee6502-30e8-45c0-b179-2b88a53029c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x126c58550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 加载数据\n",
    "# =====> 1.加载完整的原始数据集(通过非PyTorch模块的方式加载): 特征变量+标签\n",
    "X, y = tensorGenReg()\n",
    "X = X[:, :-1]\n",
    "\n",
    "# =====> 2.将完整的原始数据集以PyTorch模块的方式加载\n",
    "class tensorGenRegDataset(Dataset):  # 以数据集的名称Dataset命名该类\n",
    "    # 构造器 + 类/对象属性\n",
    "    # => 子类的对象调用父类的构造器\n",
    "    # => 在数据存储在类/对象数据字典中\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        # 计算一个完整的数据集中的样本的个数 => 标量scalar\n",
    "        self.m = len(X)\n",
    "\n",
    "    # 方法\n",
    "    # => 重写__getitem__(self, index)方法\n",
    "    # => 重写__len(self)__方法\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"根据样本的编号, 返回样本的特征变量和标签\n",
    "        @param index: 样本的编号\n",
    "        @return 样本的特征变量和标签, 存储在元组数据集结构中\n",
    "        \"\"\"\n",
    "        return self.X[index, :], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回完整数据集中样本的个数\n",
    "        \"\"\"\n",
    "        return self.m\n",
    "\n",
    "tensorGenReg_dataset = tensorGenRegDataset(X=X, y=y)\n",
    "\n",
    "# =====> 3.将完整的原始数据集按照一定的比例划分为训练数据集和测试数据集\n",
    "# 在计算机的内存中存储一个数值, 代表训练数据集中的样本数占总样本数的比例\n",
    "rate = 0.7\n",
    "# 计算训练数据集中的样本的个数 = 完整的数据集中的样本的个数 * 百分比 => 一个整数\n",
    "m_train = int(tensorGenReg_dataset.m * rate)\n",
    "# 计算测试数据集中的样本的个数 = 完整的数据集中的样本的个数 - 训练数据集中的样本的个数\n",
    "m_test = tensorGenReg_dataset.m - m_train\n",
    "# 划分\n",
    "tensorGenReg_dataset_train, tensorGenReg_dataset_test = random_split(dataset=tensorGenReg_dataset, lengths=[m_train, m_test])\n",
    "\n",
    "# =====> 4.分别对训练数据集和测试数据集按照一定的样本容量划分为若干个互不相交的子数据集\n",
    "batch_size = 10\n",
    "batched_tensorGenReg_dataset_train = DataLoader(dataset=tensorGenReg_dataset_train, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "batched_tensorGenReg_dataset_test = DataLoader(dataset=tensorGenReg_dataset_test, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a46f642a-faa5-433d-a93c-2a66e738a3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x126c58550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 搭建深度神经网络模型的架构\n",
    "# 搭建模型: 使用面向对象(定义类/创建对象)的方式 继承nn.Module类\n",
    "class GeoffNet(nn.Module):\n",
    "    \n",
    "    # 构造器 + 类/对象属性\n",
    "    # => 子类的对象调用父类的构造器\n",
    "    # => 神经网络模型中的各种层\n",
    "    def __init__(self, in_features=2, out_features=1):\n",
    "        super(GeoffNet, self).__init__()\n",
    "\n",
    "        self.output_linear = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "    \n",
    "    # 方法\n",
    "    # => 前向传播: 数据从神经网络的输入层 -> 隐藏层 -> 输出层; 逐层完成整合信息+加工信息\n",
    "    def forward(self, X):\n",
    "        # 输入层 -> 输出层\n",
    "        # 1.整合信息\n",
    "        z_hat = self.output_linear(X)  # 完成当前层上的计算过程\n",
    "        # 2.加工信息\n",
    "        return z_hat\n",
    "\n",
    "# 实例化模型\n",
    "net = GeoffNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7f08eb5-6a9c-44c2-b398-eba3aa4e0571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11e20c550>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 搭建深度神经网络模型的训练流程\n",
    "def fit(n_epochs, batched_dataset, model, criterion, optimizer):\n",
    "    \"\"\"让模型拟合数据, 在训练过程中更新模型的参数, 使得损失函数值减小, 尽可能最小\n",
    "    @param n_epochs: 对于一个完整的数据集进行学习的遍数\n",
    "    @param batched_dataset: 将一个完整的数据集按照指定的样本容量划分为若干个互不相交的子集\n",
    "    @param model: 模型\n",
    "    @param criterion: 损失函数\n",
    "    @param optimizer: 优化器\n",
    "\n",
    "    @return: 完成训练流程的模型(不一定是性能最好的模型)\n",
    "    \"\"\"\n",
    "    for i_epoch in range(n_epochs):\n",
    "        for (i_X, i_y) in batched_dataset:\n",
    "            # 1.前向传播, 计算以当前的模型参数对该批次的数据进行学习, 模型的预测输出标记\n",
    "            z_hat = model.forward(i_X)\n",
    "            # 2.计算损失, 计算模型的预测输出标记与真实标签之间的误差, 构建完整的计算图\n",
    "            loss = criterion(z_hat, i_y)\n",
    "            # 3.反向传播, 计算以当前的模型参数对应的偏导函数表达式和值, 以确定各个模型的参数在对应维度上应该向哪个方向进行更新(该维度所在的正方向or负方向)\n",
    "            loss.backward()\n",
    "            # 4.更新模型的参数, 优化器根据梯度信息, 计算当前的模型参数在各个维度的已知方向上应该更新的数值\n",
    "            optimizer.step()\n",
    "            # 5.清空梯度信息\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "# =====> 1.选择合适的损失函数. 按照一定的公式计算模型的预测输出标记和真实标签之间的误差+构造完整的计算图\n",
    "criterion = nn.MSELoss()\n",
    "# =====> 2.选择合适的优化器. 借助反向传播计算的梯度信息, 按照一定的公式更新模型中全部的参数\n",
    "eta = 0.03  # 学习率\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=eta)\n",
    "# =====> 3.开始训练\n",
    "n_epochs = 3\n",
    "fit(n_epochs=n_epochs, batched_dataset=batched_tensorGenReg_dataset_train,\n",
    "   model=net, criterion=criterion, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "940b4930-0fde-44a9-817f-ebcab9f8c4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeoffNet(\n",
       "  (output_linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取训练完的模型\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec9691c9-5ec7-4fb0-b4e4-f6089a70951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.0007, -1.0008]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0003], requires_grad=True)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取训练完的模型的参数\n",
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8ba37e4-5189-4da2-a048-91ec99df37ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[542,\n",
       " 332,\n",
       " 688,\n",
       " 949,\n",
       " 502,\n",
       " 286,\n",
       " 7,\n",
       " 275,\n",
       " 219,\n",
       " 729,\n",
       " 842,\n",
       " 650,\n",
       " 925,\n",
       " 960,\n",
       " 405,\n",
       " 85,\n",
       " 528,\n",
       " 685,\n",
       " 455,\n",
       " 82,\n",
       " 519,\n",
       " 262,\n",
       " 566,\n",
       " 41,\n",
       " 796,\n",
       " 48,\n",
       " 198,\n",
       " 706,\n",
       " 485,\n",
       " 98,\n",
       " 258,\n",
       " 702,\n",
       " 12,\n",
       " 492,\n",
       " 128,\n",
       " 489,\n",
       " 670,\n",
       " 149,\n",
       " 999,\n",
       " 524,\n",
       " 689,\n",
       " 606,\n",
       " 178,\n",
       " 181,\n",
       " 562,\n",
       " 971,\n",
       " 967,\n",
       " 785,\n",
       " 824,\n",
       " 622,\n",
       " 520,\n",
       " 869,\n",
       " 411,\n",
       " 279,\n",
       " 819,\n",
       " 69,\n",
       " 583,\n",
       " 372,\n",
       " 775,\n",
       " 899,\n",
       " 71,\n",
       " 289,\n",
       " 132,\n",
       " 65,\n",
       " 348,\n",
       " 676,\n",
       " 441,\n",
       " 601,\n",
       " 772,\n",
       " 211,\n",
       " 472,\n",
       " 776,\n",
       " 717,\n",
       " 257,\n",
       " 944,\n",
       " 312,\n",
       " 878,\n",
       " 814,\n",
       " 855,\n",
       " 458,\n",
       " 773,\n",
       " 155,\n",
       " 883,\n",
       " 710,\n",
       " 591,\n",
       " 995,\n",
       " 315,\n",
       " 43,\n",
       " 304,\n",
       " 152,\n",
       " 251,\n",
       " 470,\n",
       " 554,\n",
       " 613,\n",
       " 180,\n",
       " 370,\n",
       " 298,\n",
       " 732,\n",
       " 106,\n",
       " 491,\n",
       " 795,\n",
       " 193,\n",
       " 532,\n",
       " 529,\n",
       " 247,\n",
       " 422,\n",
       " 323,\n",
       " 417,\n",
       " 316,\n",
       " 89,\n",
       " 895,\n",
       " 983,\n",
       " 169,\n",
       " 513,\n",
       " 941,\n",
       " 408,\n",
       " 317,\n",
       " 120,\n",
       " 335,\n",
       " 134,\n",
       " 23,\n",
       " 700,\n",
       " 699,\n",
       " 957,\n",
       " 40,\n",
       " 927,\n",
       " 148,\n",
       " 445,\n",
       " 20,\n",
       " 483,\n",
       " 2,\n",
       " 567,\n",
       " 256,\n",
       " 660,\n",
       " 100,\n",
       " 826,\n",
       " 260,\n",
       " 897,\n",
       " 476,\n",
       " 604,\n",
       " 667,\n",
       " 715,\n",
       " 639,\n",
       " 816,\n",
       " 868,\n",
       " 531,\n",
       " 345,\n",
       " 537,\n",
       " 272,\n",
       " 759,\n",
       " 594,\n",
       " 937,\n",
       " 890,\n",
       " 704,\n",
       " 296,\n",
       " 26,\n",
       " 299,\n",
       " 549,\n",
       " 294,\n",
       " 782,\n",
       " 480,\n",
       " 901,\n",
       " 305,\n",
       " 13,\n",
       " 403,\n",
       " 774,\n",
       " 803,\n",
       " 708,\n",
       " 99,\n",
       " 993,\n",
       " 146,\n",
       " 822,\n",
       " 632,\n",
       " 371,\n",
       " 672,\n",
       " 160,\n",
       " 616,\n",
       " 671,\n",
       " 400,\n",
       " 625,\n",
       " 852,\n",
       " 752,\n",
       " 382,\n",
       " 153,\n",
       " 596,\n",
       " 360,\n",
       " 321,\n",
       " 734,\n",
       " 456,\n",
       " 582,\n",
       " 209,\n",
       " 172,\n",
       " 694,\n",
       " 586,\n",
       " 202,\n",
       " 356,\n",
       " 190,\n",
       " 46,\n",
       " 95,\n",
       " 407,\n",
       " 908,\n",
       " 856,\n",
       " 374,\n",
       " 284,\n",
       " 998,\n",
       " 630,\n",
       " 110,\n",
       " 721,\n",
       " 427,\n",
       " 686,\n",
       " 337,\n",
       " 131,\n",
       " 447,\n",
       " 488,\n",
       " 416,\n",
       " 851,\n",
       " 882,\n",
       " 595,\n",
       " 253,\n",
       " 633,\n",
       " 916,\n",
       " 794,\n",
       " 873,\n",
       " 690,\n",
       " 654,\n",
       " 825,\n",
       " 725,\n",
       " 195,\n",
       " 771,\n",
       " 355,\n",
       " 307,\n",
       " 522,\n",
       " 344,\n",
       " 929,\n",
       " 245,\n",
       " 924,\n",
       " 934,\n",
       " 60,\n",
       " 379,\n",
       " 223,\n",
       " 718,\n",
       " 762,\n",
       " 80,\n",
       " 154,\n",
       " 484,\n",
       " 898,\n",
       " 615,\n",
       " 862,\n",
       " 516,\n",
       " 970,\n",
       " 63,\n",
       " 290,\n",
       " 42,\n",
       " 297,\n",
       " 221,\n",
       " 306,\n",
       " 495,\n",
       " 117,\n",
       " 184,\n",
       " 997,\n",
       " 832,\n",
       " 0,\n",
       " 174,\n",
       " 823,\n",
       " 673,\n",
       " 991,\n",
       " 338,\n",
       " 449,\n",
       " 242,\n",
       " 568,\n",
       " 592,\n",
       " 716,\n",
       " 612,\n",
       " 77,\n",
       " 496,\n",
       " 249,\n",
       " 849,\n",
       " 755,\n",
       " 693,\n",
       " 129,\n",
       " 724,\n",
       " 1,\n",
       " 977,\n",
       " 626,\n",
       " 352,\n",
       " 518,\n",
       " 478,\n",
       " 912,\n",
       " 479,\n",
       " 990,\n",
       " 438,\n",
       " 452,\n",
       " 896,\n",
       " 761,\n",
       " 139,\n",
       " 108,\n",
       " 15,\n",
       " 24,\n",
       " 559,\n",
       " 384,\n",
       " 540,\n",
       " 424,\n",
       " 561,\n",
       " 943,\n",
       " 464,\n",
       " 880,\n",
       " 576,\n",
       " 56,\n",
       " 982,\n",
       " 38,\n",
       " 571,\n",
       " 777,\n",
       " 741,\n",
       " 783,\n",
       " 161,\n",
       " 649,\n",
       " 448,\n",
       " 844,\n",
       " 804,\n",
       " 340,\n",
       " 915,\n",
       " 946,\n",
       " 872,\n",
       " 837,\n",
       " 737,\n",
       " 402,\n",
       " 436,\n",
       " 871,\n",
       " 239,\n",
       " 504,\n",
       " 143,\n",
       " 22,\n",
       " 580,\n",
       " 503,\n",
       " 114,\n",
       " 792,\n",
       " 767,\n",
       " 330,\n",
       " 255,\n",
       " 950,\n",
       " 179,\n",
       " 364,\n",
       " 467,\n",
       " 900,\n",
       " 884,\n",
       " 313,\n",
       " 638,\n",
       " 953,\n",
       " 939,\n",
       " 127,\n",
       " 410,\n",
       " 243,\n",
       " 216,\n",
       " 238,\n",
       " 764,\n",
       " 135,\n",
       " 506,\n",
       " 35,\n",
       " 644,\n",
       " 648,\n",
       " 421,\n",
       " 548,\n",
       " 881,\n",
       " 265,\n",
       " 499,\n",
       " 165,\n",
       " 362,\n",
       " 177,\n",
       " 928,\n",
       " 141,\n",
       " 6,\n",
       " 555,\n",
       " 861,\n",
       " 19,\n",
       " 885,\n",
       " 111,\n",
       " 497,\n",
       " 992,\n",
       " 780,\n",
       " 828,\n",
       " 974,\n",
       " 691,\n",
       " 329,\n",
       " 451,\n",
       " 843,\n",
       " 183,\n",
       " 683,\n",
       " 460,\n",
       " 431,\n",
       " 906,\n",
       " 647,\n",
       " 923,\n",
       " 66,\n",
       " 955,\n",
       " 534,\n",
       " 55,\n",
       " 558,\n",
       " 377,\n",
       " 398,\n",
       " 758,\n",
       " 879,\n",
       " 728,\n",
       " 913,\n",
       " 678,\n",
       " 121,\n",
       " 981,\n",
       " 324,\n",
       " 194,\n",
       " 547,\n",
       " 954,\n",
       " 829,\n",
       " 655,\n",
       " 768,\n",
       " 10,\n",
       " 231,\n",
       " 847,\n",
       " 471,\n",
       " 863,\n",
       " 300,\n",
       " 635,\n",
       " 680,\n",
       " 770,\n",
       " 931,\n",
       " 419,\n",
       " 935,\n",
       " 367,\n",
       " 769,\n",
       " 786,\n",
       " 552,\n",
       " 269,\n",
       " 57,\n",
       " 662,\n",
       " 634,\n",
       " 36,\n",
       " 973,\n",
       " 207,\n",
       " 919,\n",
       " 388,\n",
       " 285,\n",
       " 237,\n",
       " 450,\n",
       " 428,\n",
       " 62,\n",
       " 319,\n",
       " 611,\n",
       " 342,\n",
       " 224,\n",
       " 745,\n",
       " 79,\n",
       " 171,\n",
       " 200,\n",
       " 437,\n",
       " 813,\n",
       " 778,\n",
       " 68,\n",
       " 867,\n",
       " 34,\n",
       " 291,\n",
       " 619,\n",
       " 610,\n",
       " 909,\n",
       " 807,\n",
       " 151,\n",
       " 536,\n",
       " 952,\n",
       " 820,\n",
       " 921,\n",
       " 545,\n",
       " 978,\n",
       " 387,\n",
       " 187,\n",
       " 975,\n",
       " 49,\n",
       " 386,\n",
       " 976,\n",
       " 142,\n",
       " 719,\n",
       " 39,\n",
       " 511,\n",
       " 603,\n",
       " 751,\n",
       " 893,\n",
       " 609,\n",
       " 112,\n",
       " 674,\n",
       " 439,\n",
       " 186,\n",
       " 659,\n",
       " 378,\n",
       " 590,\n",
       " 651,\n",
       " 750,\n",
       " 587,\n",
       " 322,\n",
       " 268,\n",
       " 841,\n",
       " 273,\n",
       " 711,\n",
       " 765,\n",
       " 76,\n",
       " 173,\n",
       " 790,\n",
       " 487,\n",
       " 756,\n",
       " 607,\n",
       " 538,\n",
       " 818,\n",
       " 37,\n",
       " 877,\n",
       " 401,\n",
       " 980,\n",
       " 505,\n",
       " 454,\n",
       " 731,\n",
       " 446,\n",
       " 215,\n",
       " 677,\n",
       " 661,\n",
       " 395,\n",
       " 743,\n",
       " 653,\n",
       " 544,\n",
       " 53,\n",
       " 61,\n",
       " 713,\n",
       " 507,\n",
       " 821,\n",
       " 473,\n",
       " 83,\n",
       " 185,\n",
       " 810,\n",
       " 726,\n",
       " 11,\n",
       " 70,\n",
       " 493,\n",
       " 665,\n",
       " 996,\n",
       " 293,\n",
       " 118,\n",
       " 210,\n",
       " 191,\n",
       " 887,\n",
       " 328,\n",
       " 490,\n",
       " 51,\n",
       " 96,\n",
       " 986,\n",
       " 392,\n",
       " 834,\n",
       " 318,\n",
       " 8,\n",
       " 509,\n",
       " 805,\n",
       " 125,\n",
       " 918,\n",
       " 133,\n",
       " 84,\n",
       " 486,\n",
       " 444,\n",
       " 501,\n",
       " 510,\n",
       " 90,\n",
       " 308,\n",
       " 932,\n",
       " 546,\n",
       " 162,\n",
       " 277,\n",
       " 746,\n",
       " 393,\n",
       " 989,\n",
       " 565,\n",
       " 799,\n",
       " 389,\n",
       " 599,\n",
       " 311,\n",
       " 292,\n",
       " 390,\n",
       " 81,\n",
       " 267,\n",
       " 827,\n",
       " 617,\n",
       " 343,\n",
       " 3,\n",
       " 875,\n",
       " 201,\n",
       " 570,\n",
       " 705,\n",
       " 109,\n",
       " 563,\n",
       " 347,\n",
       " 956,\n",
       " 749,\n",
       " 373,\n",
       " 334,\n",
       " 270,\n",
       " 564,\n",
       " 628,\n",
       " 739,\n",
       " 288,\n",
       " 640,\n",
       " 806,\n",
       " 945,\n",
       " 938,\n",
       " 754,\n",
       " 926,\n",
       " 579,\n",
       " 406,\n",
       " 246,\n",
       " 738,\n",
       " 850,\n",
       " 78,\n",
       " 461,\n",
       " 333,\n",
       " 526,\n",
       " 287,\n",
       " 157,\n",
       " 88,\n",
       " 199,\n",
       " 282,\n",
       " 602,\n",
       " 236,\n",
       " 465,\n",
       " 907,\n",
       " 47,\n",
       " 623,\n",
       " 969,\n",
       " 368,\n",
       " 703,\n",
       " 227,\n",
       " 72,\n",
       " 801,\n",
       " 339,\n",
       " 228,\n",
       " 903,\n",
       " 876,\n",
       " 517,\n",
       " 889,\n",
       " 363,\n",
       " 176,\n",
       " 533,\n",
       " 600,\n",
       " 695,\n",
       " 310,\n",
       " 314,\n",
       " 32,\n",
       " 220,\n",
       " 369,\n",
       " 830,\n",
       " 5,\n",
       " 858,\n",
       " 920,\n",
       " 156,\n",
       " 420,\n",
       " 170,\n",
       " 252,\n",
       " 637,\n",
       " 864,\n",
       " 797,\n",
       " 668,\n",
       " 376,\n",
       " 274,\n",
       " 831,\n",
       " 910,\n",
       " 229,\n",
       " 101,\n",
       " 418,\n",
       " 979,\n",
       " 281,\n",
       " 735,\n",
       " 213,\n",
       " 217,\n",
       " 629,\n",
       " 958,\n",
       " 16,\n",
       " 442,\n",
       " 44,\n",
       " 947,\n",
       " 598,\n",
       " 963,\n",
       " 327,\n",
       " 234,\n",
       " 391,\n",
       " 664,\n",
       " 233,\n",
       " 530,\n",
       " 150,\n",
       " 682,\n",
       " 409,\n",
       " 168,\n",
       " 396,\n",
       " 553,\n",
       " 475,\n",
       " 631,\n",
       " 870,\n",
       " 581,\n",
       " 854,\n",
       " 860,\n",
       " 744,\n",
       " 189,\n",
       " 527]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取训练数据集中所有样本的索引\n",
    "tensorGenReg_dataset_train.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0d1e8b91-ad6c-4eb0-97d0-8ac8347c4260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1662,  0.2457],\n",
       "         [-2.3092,  2.1917],\n",
       "         [-0.2503,  1.6936],\n",
       "         ...,\n",
       "         [ 0.8131,  0.9148],\n",
       "         [-0.9485, -0.1682],\n",
       "         [ 2.0251,  0.3138]]),\n",
       " tensor([[ 1.0714e+00],\n",
       "         [-5.8087e+00],\n",
       "         [-1.1851e+00],\n",
       "         [-1.1667e+00],\n",
       "         [-1.5329e-01],\n",
       "         [-6.9076e-01],\n",
       "         [ 2.5107e+00],\n",
       "         [ 3.9561e-01],\n",
       "         [ 3.6936e-01],\n",
       "         [ 3.5472e+00],\n",
       "         [ 9.5464e-02],\n",
       "         [ 1.4143e+00],\n",
       "         [ 1.3076e-01],\n",
       "         [-4.5490e-01],\n",
       "         [ 3.9121e+00],\n",
       "         [ 3.8458e+00],\n",
       "         [-1.1381e+00],\n",
       "         [ 6.2457e-01],\n",
       "         [-1.1852e+00],\n",
       "         [ 1.2691e+00],\n",
       "         [ 3.4679e-01],\n",
       "         [ 1.9744e+00],\n",
       "         [-8.0819e-01],\n",
       "         [ 7.6100e-01],\n",
       "         [ 5.9529e-01],\n",
       "         [-7.8521e-01],\n",
       "         [ 2.8575e+00],\n",
       "         [-1.4335e+00],\n",
       "         [ 2.9601e-01],\n",
       "         [-1.4679e-01],\n",
       "         [ 2.9899e-01],\n",
       "         [ 2.9045e+00],\n",
       "         [ 2.9154e+00],\n",
       "         [ 4.8962e+00],\n",
       "         [ 1.5278e+00],\n",
       "         [ 2.7776e+00],\n",
       "         [ 5.1009e-01],\n",
       "         [-6.8856e-01],\n",
       "         [ 1.4574e+00],\n",
       "         [ 2.2495e+00],\n",
       "         [ 1.1635e+00],\n",
       "         [-2.3283e+00],\n",
       "         [ 3.8616e+00],\n",
       "         [-8.0987e-01],\n",
       "         [ 1.5654e+00],\n",
       "         [-8.4496e-01],\n",
       "         [ 2.6455e+00],\n",
       "         [ 3.2872e+00],\n",
       "         [ 9.8202e-01],\n",
       "         [-6.5531e-01],\n",
       "         [-2.3558e+00],\n",
       "         [ 1.5045e+00],\n",
       "         [ 8.0268e-01],\n",
       "         [ 1.2813e+00],\n",
       "         [-2.7218e-01],\n",
       "         [ 5.0406e+00],\n",
       "         [-1.2826e+00],\n",
       "         [ 9.1813e-01],\n",
       "         [ 3.9059e-02],\n",
       "         [ 1.6888e+00],\n",
       "         [ 3.5227e+00],\n",
       "         [ 1.4578e+00],\n",
       "         [-2.5866e+00],\n",
       "         [ 5.4580e+00],\n",
       "         [ 1.1333e+00],\n",
       "         [ 5.0591e+00],\n",
       "         [ 7.4669e-01],\n",
       "         [-7.6463e-01],\n",
       "         [ 3.0272e-01],\n",
       "         [-1.3328e+00],\n",
       "         [-2.1653e+00],\n",
       "         [ 1.0590e+00],\n",
       "         [ 3.5831e+00],\n",
       "         [ 2.7699e+00],\n",
       "         [-8.5246e-01],\n",
       "         [-5.7676e-01],\n",
       "         [ 1.5964e+00],\n",
       "         [ 4.3365e-02],\n",
       "         [-2.6791e-01],\n",
       "         [ 1.5178e+00],\n",
       "         [ 1.4625e+00],\n",
       "         [ 4.6570e+00],\n",
       "         [-8.8799e-01],\n",
       "         [ 2.2103e-01],\n",
       "         [-7.7318e-01],\n",
       "         [ 3.7641e+00],\n",
       "         [-5.7375e-03],\n",
       "         [-5.3080e-01],\n",
       "         [ 1.6346e+00],\n",
       "         [ 2.5397e+00],\n",
       "         [ 1.3267e+00],\n",
       "         [ 8.9572e-02],\n",
       "         [-7.8433e-01],\n",
       "         [ 1.8183e+00],\n",
       "         [ 4.1312e+00],\n",
       "         [-2.4117e+00],\n",
       "         [-1.1543e-02],\n",
       "         [ 7.2997e-01],\n",
       "         [ 4.6349e-01],\n",
       "         [ 3.9627e-01],\n",
       "         [ 8.5720e-01],\n",
       "         [ 1.0578e+00],\n",
       "         [-1.1667e+00],\n",
       "         [ 2.1706e+00],\n",
       "         [-9.2047e-01],\n",
       "         [ 2.0181e+00],\n",
       "         [ 4.7855e-01],\n",
       "         [-1.1273e+00],\n",
       "         [ 2.2950e+00],\n",
       "         [ 2.8500e+00],\n",
       "         [ 1.2747e+00],\n",
       "         [-1.1244e+00],\n",
       "         [-2.6324e-01],\n",
       "         [ 1.3670e+00],\n",
       "         [ 1.2620e+00],\n",
       "         [ 1.7216e+00],\n",
       "         [ 5.0999e+00],\n",
       "         [ 6.4349e-01],\n",
       "         [ 1.0961e+00],\n",
       "         [ 2.3635e+00],\n",
       "         [-4.6729e+00],\n",
       "         [ 1.5284e+00],\n",
       "         [ 2.2039e+00],\n",
       "         [ 1.7114e+00],\n",
       "         [-2.8885e+00],\n",
       "         [ 1.8638e+00],\n",
       "         [ 1.7690e+00],\n",
       "         [-1.3188e-01],\n",
       "         [-8.4835e-01],\n",
       "         [ 3.1374e-01],\n",
       "         [ 2.7814e+00],\n",
       "         [ 3.6855e+00],\n",
       "         [ 1.7508e+00],\n",
       "         [ 3.0583e+00],\n",
       "         [ 2.2031e+00],\n",
       "         [-1.7485e+00],\n",
       "         [ 3.1192e+00],\n",
       "         [-4.9081e-01],\n",
       "         [-5.9567e-01],\n",
       "         [ 1.5112e+00],\n",
       "         [ 1.4953e+00],\n",
       "         [-1.6602e+00],\n",
       "         [-1.9625e+00],\n",
       "         [-5.1877e+00],\n",
       "         [ 2.5594e+00],\n",
       "         [ 5.8961e+00],\n",
       "         [ 3.6066e-01],\n",
       "         [ 2.5065e-01],\n",
       "         [ 2.9090e+00],\n",
       "         [ 4.2393e+00],\n",
       "         [ 1.3785e+00],\n",
       "         [ 3.4949e+00],\n",
       "         [ 1.1067e+00],\n",
       "         [ 4.7793e-01],\n",
       "         [-1.5709e+00],\n",
       "         [ 1.7803e+00],\n",
       "         [ 5.2860e+00],\n",
       "         [-3.5450e+00],\n",
       "         [ 1.0324e+00],\n",
       "         [ 2.2781e+00],\n",
       "         [ 1.5206e+00],\n",
       "         [ 4.3113e+00],\n",
       "         [ 3.5484e+00],\n",
       "         [ 2.2670e+00],\n",
       "         [ 2.0982e+00],\n",
       "         [ 3.4562e+00],\n",
       "         [-2.0458e+00],\n",
       "         [ 2.9909e+00],\n",
       "         [-6.8721e-01],\n",
       "         [ 1.1554e+00],\n",
       "         [ 1.1520e+00],\n",
       "         [ 6.7223e-02],\n",
       "         [-7.9379e-01],\n",
       "         [ 1.1278e-01],\n",
       "         [-1.6769e-01],\n",
       "         [ 1.4615e+00],\n",
       "         [ 4.3637e+00],\n",
       "         [ 1.9752e+00],\n",
       "         [ 4.7153e+00],\n",
       "         [ 3.1941e-01],\n",
       "         [ 5.2477e+00],\n",
       "         [ 6.8657e+00],\n",
       "         [ 4.8654e-01],\n",
       "         [ 2.2217e+00],\n",
       "         [ 4.0905e+00],\n",
       "         [-5.2456e-01],\n",
       "         [-6.4322e-01],\n",
       "         [-3.3274e-01],\n",
       "         [ 4.2741e+00],\n",
       "         [-1.8639e+00],\n",
       "         [ 1.5933e+00],\n",
       "         [ 5.6065e-01],\n",
       "         [-1.3504e+00],\n",
       "         [ 3.1693e+00],\n",
       "         [ 2.8597e+00],\n",
       "         [ 1.3842e+00],\n",
       "         [-5.7305e-01],\n",
       "         [ 6.1114e+00],\n",
       "         [ 5.8353e-02],\n",
       "         [-1.8740e+00],\n",
       "         [ 1.3899e+00],\n",
       "         [ 2.2021e+00],\n",
       "         [ 1.0166e+00],\n",
       "         [-2.5544e+00],\n",
       "         [ 1.7494e+00],\n",
       "         [-2.1158e-01],\n",
       "         [-1.5619e+00],\n",
       "         [-2.9845e-01],\n",
       "         [ 1.5378e-01],\n",
       "         [-3.1332e+00],\n",
       "         [ 1.0376e+00],\n",
       "         [ 8.2208e-01],\n",
       "         [ 2.0813e+00],\n",
       "         [ 2.3672e-01],\n",
       "         [ 4.9993e+00],\n",
       "         [ 3.5120e-01],\n",
       "         [ 3.2408e+00],\n",
       "         [ 3.2063e-01],\n",
       "         [ 1.6122e+00],\n",
       "         [ 5.8046e+00],\n",
       "         [-1.5943e-01],\n",
       "         [ 1.7464e-01],\n",
       "         [ 4.4771e+00],\n",
       "         [ 3.0241e+00],\n",
       "         [ 2.7004e+00],\n",
       "         [ 4.6435e+00],\n",
       "         [ 6.9700e-01],\n",
       "         [ 1.8476e+00],\n",
       "         [ 4.2091e+00],\n",
       "         [ 2.9601e+00],\n",
       "         [ 4.8279e-01],\n",
       "         [-7.9430e-01],\n",
       "         [ 1.5287e+00],\n",
       "         [ 3.7180e+00],\n",
       "         [-2.2567e+00],\n",
       "         [ 3.3128e+00],\n",
       "         [ 2.4694e+00],\n",
       "         [-5.0052e-01],\n",
       "         [ 2.4341e+00],\n",
       "         [-1.3560e+00],\n",
       "         [-2.0002e-01],\n",
       "         [ 2.9551e+00],\n",
       "         [-1.8369e+00],\n",
       "         [-1.8248e+00],\n",
       "         [ 7.8301e-01],\n",
       "         [ 1.1327e+00],\n",
       "         [-4.3810e-01],\n",
       "         [-1.4988e+00],\n",
       "         [ 4.4638e-01],\n",
       "         [ 7.7017e-01],\n",
       "         [ 4.7838e-01],\n",
       "         [ 4.3182e+00],\n",
       "         [-7.9940e-01],\n",
       "         [-2.6464e+00],\n",
       "         [-1.7534e+00],\n",
       "         [ 3.6862e+00],\n",
       "         [ 2.2287e+00],\n",
       "         [-6.1660e-02],\n",
       "         [-3.2785e+00],\n",
       "         [ 1.2833e+00],\n",
       "         [ 6.8450e-01],\n",
       "         [ 3.8257e+00],\n",
       "         [-1.6803e-01],\n",
       "         [-2.9509e+00],\n",
       "         [ 4.8378e-01],\n",
       "         [ 1.2861e-01],\n",
       "         [ 3.1848e+00],\n",
       "         [ 1.9907e+00],\n",
       "         [ 6.1435e+00],\n",
       "         [ 3.2274e+00],\n",
       "         [ 1.5595e-01],\n",
       "         [ 1.4834e+00],\n",
       "         [ 5.2740e-01],\n",
       "         [-1.5019e+00],\n",
       "         [ 8.0226e-01],\n",
       "         [ 2.9068e+00],\n",
       "         [-6.9011e-01],\n",
       "         [ 1.2157e+00],\n",
       "         [-1.1850e+00],\n",
       "         [ 3.4763e-01],\n",
       "         [-8.8320e-01],\n",
       "         [ 2.5079e+00],\n",
       "         [ 3.7419e-01],\n",
       "         [ 1.8305e+00],\n",
       "         [ 7.1764e+00],\n",
       "         [-4.0200e-01],\n",
       "         [ 1.6595e+00],\n",
       "         [-1.7947e-01],\n",
       "         [ 1.6356e+00],\n",
       "         [ 3.6735e+00],\n",
       "         [ 2.9437e+00],\n",
       "         [-1.8972e+00],\n",
       "         [ 2.7908e-02],\n",
       "         [-1.2332e+00],\n",
       "         [ 3.7722e+00],\n",
       "         [ 3.1884e+00],\n",
       "         [ 2.5609e+00],\n",
       "         [-5.7032e+00],\n",
       "         [-1.0254e+00],\n",
       "         [ 2.9246e+00],\n",
       "         [ 6.6810e-01],\n",
       "         [ 3.3937e+00],\n",
       "         [ 2.6867e+00],\n",
       "         [ 3.2779e+00],\n",
       "         [ 2.4712e+00],\n",
       "         [ 5.4572e-01],\n",
       "         [ 2.8364e+00],\n",
       "         [ 1.7477e+00],\n",
       "         [-1.9919e+00],\n",
       "         [-2.5766e+00],\n",
       "         [ 2.3304e+00],\n",
       "         [ 1.8466e+00],\n",
       "         [ 8.4831e-01],\n",
       "         [ 2.7465e+00],\n",
       "         [ 2.7991e+00],\n",
       "         [-1.1837e+00],\n",
       "         [ 2.9547e+00],\n",
       "         [ 4.8557e-01],\n",
       "         [-5.3915e-01],\n",
       "         [ 1.4279e+00],\n",
       "         [ 1.8394e-01],\n",
       "         [-1.4841e+00],\n",
       "         [ 9.9976e-01],\n",
       "         [ 1.1277e+00],\n",
       "         [ 5.7284e-01],\n",
       "         [-9.5462e-01],\n",
       "         [ 6.3942e-02],\n",
       "         [-9.5550e-01],\n",
       "         [ 9.8961e-01],\n",
       "         [ 3.3685e+00],\n",
       "         [ 1.2262e+00],\n",
       "         [ 1.3798e+00],\n",
       "         [ 5.5719e+00],\n",
       "         [ 2.1099e+00],\n",
       "         [-1.0400e+00],\n",
       "         [ 2.1808e+00],\n",
       "         [ 2.6846e+00],\n",
       "         [ 2.7794e+00],\n",
       "         [-6.9684e-01],\n",
       "         [ 2.0285e+00],\n",
       "         [-3.4012e+00],\n",
       "         [ 1.7980e+00],\n",
       "         [ 1.2829e+00],\n",
       "         [ 1.0652e-01],\n",
       "         [ 9.4051e-01],\n",
       "         [ 4.7830e+00],\n",
       "         [-1.0551e+00],\n",
       "         [ 3.2331e+00],\n",
       "         [ 1.0180e+00],\n",
       "         [ 1.7618e+00],\n",
       "         [ 1.6824e+00],\n",
       "         [-5.9598e-01],\n",
       "         [-3.3086e-01],\n",
       "         [ 4.3085e-01],\n",
       "         [-2.0450e+00],\n",
       "         [ 5.8807e-01],\n",
       "         [ 1.3846e+00],\n",
       "         [ 5.5749e+00],\n",
       "         [-1.1637e+00],\n",
       "         [ 2.8659e+00],\n",
       "         [ 8.6568e-01],\n",
       "         [ 3.7061e+00],\n",
       "         [ 3.3458e+00],\n",
       "         [ 2.7676e+00],\n",
       "         [ 2.2809e+00],\n",
       "         [ 3.9640e+00],\n",
       "         [-8.3383e-01],\n",
       "         [-4.0092e-01],\n",
       "         [ 3.8483e+00],\n",
       "         [ 2.0049e+00],\n",
       "         [-1.3692e+00],\n",
       "         [-2.3819e+00],\n",
       "         [-1.2504e-01],\n",
       "         [ 5.7875e+00],\n",
       "         [-2.1723e+00],\n",
       "         [ 2.9702e+00],\n",
       "         [ 1.4559e+00],\n",
       "         [-1.7663e+00],\n",
       "         [ 1.6293e+00],\n",
       "         [-4.2516e-01],\n",
       "         [ 5.2575e+00],\n",
       "         [-1.8885e+00],\n",
       "         [-2.7328e+00],\n",
       "         [-3.8488e+00],\n",
       "         [-9.4295e-01],\n",
       "         [-1.3798e+00],\n",
       "         [-1.6145e-01],\n",
       "         [-1.6230e+00],\n",
       "         [ 5.5532e-01],\n",
       "         [ 4.0581e+00],\n",
       "         [-7.3849e-02],\n",
       "         [-6.5114e-01],\n",
       "         [-2.5629e+00],\n",
       "         [ 9.5926e-01],\n",
       "         [ 1.5075e+00],\n",
       "         [-6.6593e-01],\n",
       "         [ 2.3918e+00],\n",
       "         [-9.6939e-02],\n",
       "         [-1.6641e+00],\n",
       "         [-3.0509e+00],\n",
       "         [ 1.3175e+00],\n",
       "         [ 3.4038e+00],\n",
       "         [ 9.3493e-01],\n",
       "         [-8.4189e-01],\n",
       "         [-1.1204e+00],\n",
       "         [-5.7423e-01],\n",
       "         [ 2.1631e+00],\n",
       "         [ 1.5883e-01],\n",
       "         [ 1.5961e+00],\n",
       "         [ 2.4116e+00],\n",
       "         [ 1.6952e-01],\n",
       "         [ 2.1952e-01],\n",
       "         [-1.2117e+00],\n",
       "         [ 9.8198e-01],\n",
       "         [ 5.3756e-01],\n",
       "         [ 2.4235e+00],\n",
       "         [-5.3830e-01],\n",
       "         [-7.7480e-01],\n",
       "         [ 1.2437e+00],\n",
       "         [ 3.2141e-01],\n",
       "         [ 1.0576e+00],\n",
       "         [-1.3878e+00],\n",
       "         [ 2.9861e+00],\n",
       "         [ 1.7978e+00],\n",
       "         [ 1.6018e+00],\n",
       "         [-8.4108e-01],\n",
       "         [ 1.7261e-01],\n",
       "         [ 2.0685e-01],\n",
       "         [ 1.6089e+00],\n",
       "         [ 1.4498e+00],\n",
       "         [ 2.8335e+00],\n",
       "         [-1.0564e+00],\n",
       "         [ 3.9306e+00],\n",
       "         [ 3.2032e+00],\n",
       "         [-2.1514e+00],\n",
       "         [ 1.6137e+00],\n",
       "         [ 3.7799e+00],\n",
       "         [ 1.7209e+00],\n",
       "         [ 2.7919e+00],\n",
       "         [-2.1385e+00],\n",
       "         [-9.1988e-01],\n",
       "         [-1.1222e+00],\n",
       "         [ 4.1183e+00],\n",
       "         [-1.0077e+00],\n",
       "         [-4.0801e-02],\n",
       "         [ 1.4198e+00],\n",
       "         [ 4.5516e-01],\n",
       "         [ 3.0093e+00],\n",
       "         [ 9.6620e-01],\n",
       "         [ 6.6300e-01],\n",
       "         [-3.2778e+00],\n",
       "         [-4.8502e-01],\n",
       "         [ 2.2923e+00],\n",
       "         [ 3.1684e+00],\n",
       "         [ 9.9021e-01],\n",
       "         [ 2.4190e+00],\n",
       "         [ 2.1137e+00],\n",
       "         [ 2.5685e+00],\n",
       "         [ 1.0601e+00],\n",
       "         [-1.6876e+00],\n",
       "         [-1.0093e-01],\n",
       "         [ 4.4118e-01],\n",
       "         [ 1.9948e+00],\n",
       "         [-1.2674e+00],\n",
       "         [ 3.1094e+00],\n",
       "         [ 1.7661e+00],\n",
       "         [ 1.6241e+00],\n",
       "         [-1.7055e+00],\n",
       "         [-8.7558e-01],\n",
       "         [ 7.4977e-01],\n",
       "         [ 1.1171e+00],\n",
       "         [-1.1937e-01],\n",
       "         [-1.8004e+00],\n",
       "         [ 2.5201e+00],\n",
       "         [ 5.5662e+00],\n",
       "         [ 2.6555e+00],\n",
       "         [ 4.3230e+00],\n",
       "         [ 3.7898e-01],\n",
       "         [ 4.3282e-01],\n",
       "         [ 2.3208e-01],\n",
       "         [ 9.9198e-01],\n",
       "         [-2.7607e+00],\n",
       "         [-6.9306e-01],\n",
       "         [ 1.1910e+00],\n",
       "         [-1.0042e+00],\n",
       "         [ 1.6128e+00],\n",
       "         [ 1.6264e+00],\n",
       "         [-1.2760e+00],\n",
       "         [-1.2612e+00],\n",
       "         [ 1.9175e+00],\n",
       "         [ 3.0227e+00],\n",
       "         [-3.5556e-02],\n",
       "         [ 5.2238e+00],\n",
       "         [ 5.2975e+00],\n",
       "         [-1.6055e+00],\n",
       "         [ 7.2551e+00],\n",
       "         [ 1.5052e+00],\n",
       "         [ 1.1342e+00],\n",
       "         [ 1.4382e+00],\n",
       "         [-5.1078e-01],\n",
       "         [-2.6675e+00],\n",
       "         [ 2.0057e-01],\n",
       "         [-6.2801e+00],\n",
       "         [ 2.1518e+00],\n",
       "         [ 1.8875e+00],\n",
       "         [ 3.8343e+00],\n",
       "         [ 1.7142e+00],\n",
       "         [-2.3906e-02],\n",
       "         [-3.8784e-01],\n",
       "         [ 6.3085e+00],\n",
       "         [ 1.8861e+00],\n",
       "         [-6.9997e-01],\n",
       "         [ 7.0214e-01],\n",
       "         [ 1.6916e+00],\n",
       "         [ 2.6037e+00],\n",
       "         [ 5.1832e+00],\n",
       "         [ 1.6939e+00],\n",
       "         [ 6.2394e-02],\n",
       "         [-1.7053e+00],\n",
       "         [-2.5665e+00],\n",
       "         [ 1.2553e+00],\n",
       "         [ 1.4051e+00],\n",
       "         [ 4.3313e+00],\n",
       "         [ 1.9724e+00],\n",
       "         [-9.7732e-01],\n",
       "         [-3.5979e+00],\n",
       "         [-1.0273e+00],\n",
       "         [ 1.3028e+00],\n",
       "         [ 4.8363e+00],\n",
       "         [-1.7214e+00],\n",
       "         [ 2.6419e+00],\n",
       "         [ 8.2102e-01],\n",
       "         [ 2.7693e+00],\n",
       "         [-2.6379e-01],\n",
       "         [ 4.4854e+00],\n",
       "         [ 1.0252e+00],\n",
       "         [ 5.0836e+00],\n",
       "         [ 2.1608e+00],\n",
       "         [-1.3026e+00],\n",
       "         [ 3.0730e+00],\n",
       "         [-2.7764e-01],\n",
       "         [ 9.3131e-01],\n",
       "         [ 1.2252e+00],\n",
       "         [ 1.2769e+00],\n",
       "         [-1.0359e+00],\n",
       "         [ 7.2720e-01],\n",
       "         [-2.1850e+00],\n",
       "         [-1.5091e+00],\n",
       "         [ 1.0465e+00],\n",
       "         [ 4.9220e-01],\n",
       "         [-5.8972e-01],\n",
       "         [-8.8701e-01],\n",
       "         [ 3.2925e+00],\n",
       "         [ 2.0600e+00],\n",
       "         [ 3.8884e+00],\n",
       "         [ 2.0713e+00],\n",
       "         [-4.2138e+00],\n",
       "         [ 1.6000e+00],\n",
       "         [ 7.4632e+00],\n",
       "         [ 2.3851e+00],\n",
       "         [ 4.3262e+00],\n",
       "         [-8.5155e-01],\n",
       "         [ 4.4822e+00],\n",
       "         [ 7.4347e-01],\n",
       "         [ 3.5848e-03],\n",
       "         [ 1.8410e+00],\n",
       "         [ 4.9387e-01],\n",
       "         [ 4.5958e+00],\n",
       "         [ 1.5948e+00],\n",
       "         [ 1.0776e+00],\n",
       "         [-4.6241e-01],\n",
       "         [ 3.0907e+00],\n",
       "         [-4.4502e-01],\n",
       "         [-4.7873e-01],\n",
       "         [-1.2899e+00],\n",
       "         [-3.6759e-01],\n",
       "         [ 4.8300e-01],\n",
       "         [ 1.6694e+00],\n",
       "         [-1.1058e+00],\n",
       "         [-1.5774e-01],\n",
       "         [-4.1796e+00],\n",
       "         [ 8.1604e-01],\n",
       "         [-3.5859e-01],\n",
       "         [ 2.4796e+00],\n",
       "         [ 2.6519e+00],\n",
       "         [ 6.2422e+00],\n",
       "         [-1.0323e+00],\n",
       "         [ 1.3090e+00],\n",
       "         [-9.8641e-01],\n",
       "         [-1.7379e+00],\n",
       "         [ 1.7790e+00],\n",
       "         [-7.5182e-01],\n",
       "         [ 2.9519e-01],\n",
       "         [ 1.0277e+00],\n",
       "         [ 1.9957e-01],\n",
       "         [ 1.8730e-02],\n",
       "         [ 3.5109e+00],\n",
       "         [ 1.5336e+00],\n",
       "         [-3.5899e+00],\n",
       "         [ 5.5146e-01],\n",
       "         [ 2.0185e+00],\n",
       "         [ 9.0811e-01],\n",
       "         [ 2.0605e+00],\n",
       "         [-1.2391e+00],\n",
       "         [-2.9734e-01],\n",
       "         [ 3.6075e+00],\n",
       "         [-1.3415e+00],\n",
       "         [ 3.5240e+00],\n",
       "         [ 4.6051e+00],\n",
       "         [ 2.6849e+00],\n",
       "         [-3.2952e+00],\n",
       "         [-1.7300e+00],\n",
       "         [-9.5466e-01],\n",
       "         [ 6.1910e-01],\n",
       "         [ 1.0403e+00],\n",
       "         [ 5.9173e+00],\n",
       "         [ 2.1918e+00],\n",
       "         [ 8.1355e-01],\n",
       "         [ 7.3629e-01],\n",
       "         [ 2.2301e+00],\n",
       "         [ 3.5561e+00],\n",
       "         [-1.5015e+00],\n",
       "         [ 2.3782e+00],\n",
       "         [ 1.6807e+00],\n",
       "         [-1.2408e+00],\n",
       "         [ 1.1585e+00],\n",
       "         [ 2.1024e+00],\n",
       "         [-3.7811e+00],\n",
       "         [-3.0201e+00],\n",
       "         [ 1.4569e+00],\n",
       "         [ 8.1534e-01],\n",
       "         [ 2.0640e+00],\n",
       "         [-3.0288e+00],\n",
       "         [-1.7039e+00],\n",
       "         [-5.2862e-01],\n",
       "         [-3.4043e+00],\n",
       "         [ 5.1064e-01],\n",
       "         [ 5.3970e+00],\n",
       "         [-1.2954e+00],\n",
       "         [-1.2131e+00],\n",
       "         [ 2.9491e+00],\n",
       "         [ 1.2664e+00],\n",
       "         [ 1.4940e+00],\n",
       "         [-1.2948e+00],\n",
       "         [ 9.3775e-01],\n",
       "         [ 5.3518e+00],\n",
       "         [ 2.2205e+00],\n",
       "         [ 1.8419e+00],\n",
       "         [ 2.4415e+00],\n",
       "         [-6.1323e-01],\n",
       "         [-1.7991e+00],\n",
       "         [ 1.3282e+00],\n",
       "         [ 3.1418e+00],\n",
       "         [-3.5430e+00],\n",
       "         [ 4.1476e-01],\n",
       "         [-7.4519e-01],\n",
       "         [ 1.3250e+00],\n",
       "         [ 5.0016e-01],\n",
       "         [ 2.9520e+00],\n",
       "         [ 5.5095e-01],\n",
       "         [-1.6538e+00],\n",
       "         [ 4.8246e+00],\n",
       "         [-2.9954e+00],\n",
       "         [ 1.2296e+00],\n",
       "         [ 2.4661e+00],\n",
       "         [ 2.2219e-02],\n",
       "         [ 1.9525e+00],\n",
       "         [ 6.5162e-01],\n",
       "         [ 1.1183e+00],\n",
       "         [ 5.2490e-01],\n",
       "         [ 2.8464e+00],\n",
       "         [ 1.5024e+00],\n",
       "         [-9.6524e-01],\n",
       "         [-1.4516e+00],\n",
       "         [ 3.3874e+00],\n",
       "         [ 4.6463e+00],\n",
       "         [ 5.3794e+00],\n",
       "         [ 3.7319e+00],\n",
       "         [ 3.6324e-01],\n",
       "         [ 3.8884e+00],\n",
       "         [-1.4583e-01],\n",
       "         [-2.4385e+00],\n",
       "         [-6.1594e-01],\n",
       "         [ 3.1368e+00],\n",
       "         [ 1.8553e+00],\n",
       "         [-3.0963e+00],\n",
       "         [ 3.2664e+00],\n",
       "         [-2.4521e+00],\n",
       "         [-3.1796e+00],\n",
       "         [ 3.0407e+00],\n",
       "         [-1.4830e+00],\n",
       "         [-1.4485e+00],\n",
       "         [-2.1534e+00],\n",
       "         [ 4.0918e+00],\n",
       "         [-2.3005e+00],\n",
       "         [ 2.0446e+00],\n",
       "         [-2.2714e+00],\n",
       "         [ 1.7069e+00],\n",
       "         [-7.3087e-01],\n",
       "         [ 4.7447e+00]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从完整的数据集中通过训练数据集中样本的索引, 获取训练数据集\n",
    "tensorGenReg_dataset[tensorGenReg_dataset_train.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "318b2f1b-678d-4181-8699-aecd24dd90bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensorGenReg_dataset[tensorGenReg_dataset_train.indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ffb19333-7568-4e85-9f6a-adae34902a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensorGenReg_dataset[tensorGenReg_dataset_train.indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "922e750a-a3c4-4c7d-9307-245e32f20fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1662,  0.2457],\n",
       "        [-2.3092,  2.1917],\n",
       "        [-0.2503,  1.6936],\n",
       "        ...,\n",
       "        [ 0.8131,  0.9148],\n",
       "        [-0.9485, -0.1682],\n",
       "        [ 2.0251,  0.3138]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取训练数据集的特征变量\n",
    "tensorGenReg_dataset[tensorGenReg_dataset_train.indices][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "101e5f75-3938-4878-89f0-146f5342ae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0714e+00],\n",
       "        [-5.8087e+00],\n",
       "        [-1.1851e+00],\n",
       "        [-1.1667e+00],\n",
       "        [-1.5329e-01],\n",
       "        [-6.9076e-01],\n",
       "        [ 2.5107e+00],\n",
       "        [ 3.9561e-01],\n",
       "        [ 3.6936e-01],\n",
       "        [ 3.5472e+00],\n",
       "        [ 9.5464e-02],\n",
       "        [ 1.4143e+00],\n",
       "        [ 1.3076e-01],\n",
       "        [-4.5490e-01],\n",
       "        [ 3.9121e+00],\n",
       "        [ 3.8458e+00],\n",
       "        [-1.1381e+00],\n",
       "        [ 6.2457e-01],\n",
       "        [-1.1852e+00],\n",
       "        [ 1.2691e+00],\n",
       "        [ 3.4679e-01],\n",
       "        [ 1.9744e+00],\n",
       "        [-8.0819e-01],\n",
       "        [ 7.6100e-01],\n",
       "        [ 5.9529e-01],\n",
       "        [-7.8521e-01],\n",
       "        [ 2.8575e+00],\n",
       "        [-1.4335e+00],\n",
       "        [ 2.9601e-01],\n",
       "        [-1.4679e-01],\n",
       "        [ 2.9899e-01],\n",
       "        [ 2.9045e+00],\n",
       "        [ 2.9154e+00],\n",
       "        [ 4.8962e+00],\n",
       "        [ 1.5278e+00],\n",
       "        [ 2.7776e+00],\n",
       "        [ 5.1009e-01],\n",
       "        [-6.8856e-01],\n",
       "        [ 1.4574e+00],\n",
       "        [ 2.2495e+00],\n",
       "        [ 1.1635e+00],\n",
       "        [-2.3283e+00],\n",
       "        [ 3.8616e+00],\n",
       "        [-8.0987e-01],\n",
       "        [ 1.5654e+00],\n",
       "        [-8.4496e-01],\n",
       "        [ 2.6455e+00],\n",
       "        [ 3.2872e+00],\n",
       "        [ 9.8202e-01],\n",
       "        [-6.5531e-01],\n",
       "        [-2.3558e+00],\n",
       "        [ 1.5045e+00],\n",
       "        [ 8.0268e-01],\n",
       "        [ 1.2813e+00],\n",
       "        [-2.7218e-01],\n",
       "        [ 5.0406e+00],\n",
       "        [-1.2826e+00],\n",
       "        [ 9.1813e-01],\n",
       "        [ 3.9059e-02],\n",
       "        [ 1.6888e+00],\n",
       "        [ 3.5227e+00],\n",
       "        [ 1.4578e+00],\n",
       "        [-2.5866e+00],\n",
       "        [ 5.4580e+00],\n",
       "        [ 1.1333e+00],\n",
       "        [ 5.0591e+00],\n",
       "        [ 7.4669e-01],\n",
       "        [-7.6463e-01],\n",
       "        [ 3.0272e-01],\n",
       "        [-1.3328e+00],\n",
       "        [-2.1653e+00],\n",
       "        [ 1.0590e+00],\n",
       "        [ 3.5831e+00],\n",
       "        [ 2.7699e+00],\n",
       "        [-8.5246e-01],\n",
       "        [-5.7676e-01],\n",
       "        [ 1.5964e+00],\n",
       "        [ 4.3365e-02],\n",
       "        [-2.6791e-01],\n",
       "        [ 1.5178e+00],\n",
       "        [ 1.4625e+00],\n",
       "        [ 4.6570e+00],\n",
       "        [-8.8799e-01],\n",
       "        [ 2.2103e-01],\n",
       "        [-7.7318e-01],\n",
       "        [ 3.7641e+00],\n",
       "        [-5.7375e-03],\n",
       "        [-5.3080e-01],\n",
       "        [ 1.6346e+00],\n",
       "        [ 2.5397e+00],\n",
       "        [ 1.3267e+00],\n",
       "        [ 8.9572e-02],\n",
       "        [-7.8433e-01],\n",
       "        [ 1.8183e+00],\n",
       "        [ 4.1312e+00],\n",
       "        [-2.4117e+00],\n",
       "        [-1.1543e-02],\n",
       "        [ 7.2997e-01],\n",
       "        [ 4.6349e-01],\n",
       "        [ 3.9627e-01],\n",
       "        [ 8.5720e-01],\n",
       "        [ 1.0578e+00],\n",
       "        [-1.1667e+00],\n",
       "        [ 2.1706e+00],\n",
       "        [-9.2047e-01],\n",
       "        [ 2.0181e+00],\n",
       "        [ 4.7855e-01],\n",
       "        [-1.1273e+00],\n",
       "        [ 2.2950e+00],\n",
       "        [ 2.8500e+00],\n",
       "        [ 1.2747e+00],\n",
       "        [-1.1244e+00],\n",
       "        [-2.6324e-01],\n",
       "        [ 1.3670e+00],\n",
       "        [ 1.2620e+00],\n",
       "        [ 1.7216e+00],\n",
       "        [ 5.0999e+00],\n",
       "        [ 6.4349e-01],\n",
       "        [ 1.0961e+00],\n",
       "        [ 2.3635e+00],\n",
       "        [-4.6729e+00],\n",
       "        [ 1.5284e+00],\n",
       "        [ 2.2039e+00],\n",
       "        [ 1.7114e+00],\n",
       "        [-2.8885e+00],\n",
       "        [ 1.8638e+00],\n",
       "        [ 1.7690e+00],\n",
       "        [-1.3188e-01],\n",
       "        [-8.4835e-01],\n",
       "        [ 3.1374e-01],\n",
       "        [ 2.7814e+00],\n",
       "        [ 3.6855e+00],\n",
       "        [ 1.7508e+00],\n",
       "        [ 3.0583e+00],\n",
       "        [ 2.2031e+00],\n",
       "        [-1.7485e+00],\n",
       "        [ 3.1192e+00],\n",
       "        [-4.9081e-01],\n",
       "        [-5.9567e-01],\n",
       "        [ 1.5112e+00],\n",
       "        [ 1.4953e+00],\n",
       "        [-1.6602e+00],\n",
       "        [-1.9625e+00],\n",
       "        [-5.1877e+00],\n",
       "        [ 2.5594e+00],\n",
       "        [ 5.8961e+00],\n",
       "        [ 3.6066e-01],\n",
       "        [ 2.5065e-01],\n",
       "        [ 2.9090e+00],\n",
       "        [ 4.2393e+00],\n",
       "        [ 1.3785e+00],\n",
       "        [ 3.4949e+00],\n",
       "        [ 1.1067e+00],\n",
       "        [ 4.7793e-01],\n",
       "        [-1.5709e+00],\n",
       "        [ 1.7803e+00],\n",
       "        [ 5.2860e+00],\n",
       "        [-3.5450e+00],\n",
       "        [ 1.0324e+00],\n",
       "        [ 2.2781e+00],\n",
       "        [ 1.5206e+00],\n",
       "        [ 4.3113e+00],\n",
       "        [ 3.5484e+00],\n",
       "        [ 2.2670e+00],\n",
       "        [ 2.0982e+00],\n",
       "        [ 3.4562e+00],\n",
       "        [-2.0458e+00],\n",
       "        [ 2.9909e+00],\n",
       "        [-6.8721e-01],\n",
       "        [ 1.1554e+00],\n",
       "        [ 1.1520e+00],\n",
       "        [ 6.7223e-02],\n",
       "        [-7.9379e-01],\n",
       "        [ 1.1278e-01],\n",
       "        [-1.6769e-01],\n",
       "        [ 1.4615e+00],\n",
       "        [ 4.3637e+00],\n",
       "        [ 1.9752e+00],\n",
       "        [ 4.7153e+00],\n",
       "        [ 3.1941e-01],\n",
       "        [ 5.2477e+00],\n",
       "        [ 6.8657e+00],\n",
       "        [ 4.8654e-01],\n",
       "        [ 2.2217e+00],\n",
       "        [ 4.0905e+00],\n",
       "        [-5.2456e-01],\n",
       "        [-6.4322e-01],\n",
       "        [-3.3274e-01],\n",
       "        [ 4.2741e+00],\n",
       "        [-1.8639e+00],\n",
       "        [ 1.5933e+00],\n",
       "        [ 5.6065e-01],\n",
       "        [-1.3504e+00],\n",
       "        [ 3.1693e+00],\n",
       "        [ 2.8597e+00],\n",
       "        [ 1.3842e+00],\n",
       "        [-5.7305e-01],\n",
       "        [ 6.1114e+00],\n",
       "        [ 5.8353e-02],\n",
       "        [-1.8740e+00],\n",
       "        [ 1.3899e+00],\n",
       "        [ 2.2021e+00],\n",
       "        [ 1.0166e+00],\n",
       "        [-2.5544e+00],\n",
       "        [ 1.7494e+00],\n",
       "        [-2.1158e-01],\n",
       "        [-1.5619e+00],\n",
       "        [-2.9845e-01],\n",
       "        [ 1.5378e-01],\n",
       "        [-3.1332e+00],\n",
       "        [ 1.0376e+00],\n",
       "        [ 8.2208e-01],\n",
       "        [ 2.0813e+00],\n",
       "        [ 2.3672e-01],\n",
       "        [ 4.9993e+00],\n",
       "        [ 3.5120e-01],\n",
       "        [ 3.2408e+00],\n",
       "        [ 3.2063e-01],\n",
       "        [ 1.6122e+00],\n",
       "        [ 5.8046e+00],\n",
       "        [-1.5943e-01],\n",
       "        [ 1.7464e-01],\n",
       "        [ 4.4771e+00],\n",
       "        [ 3.0241e+00],\n",
       "        [ 2.7004e+00],\n",
       "        [ 4.6435e+00],\n",
       "        [ 6.9700e-01],\n",
       "        [ 1.8476e+00],\n",
       "        [ 4.2091e+00],\n",
       "        [ 2.9601e+00],\n",
       "        [ 4.8279e-01],\n",
       "        [-7.9430e-01],\n",
       "        [ 1.5287e+00],\n",
       "        [ 3.7180e+00],\n",
       "        [-2.2567e+00],\n",
       "        [ 3.3128e+00],\n",
       "        [ 2.4694e+00],\n",
       "        [-5.0052e-01],\n",
       "        [ 2.4341e+00],\n",
       "        [-1.3560e+00],\n",
       "        [-2.0002e-01],\n",
       "        [ 2.9551e+00],\n",
       "        [-1.8369e+00],\n",
       "        [-1.8248e+00],\n",
       "        [ 7.8301e-01],\n",
       "        [ 1.1327e+00],\n",
       "        [-4.3810e-01],\n",
       "        [-1.4988e+00],\n",
       "        [ 4.4638e-01],\n",
       "        [ 7.7017e-01],\n",
       "        [ 4.7838e-01],\n",
       "        [ 4.3182e+00],\n",
       "        [-7.9940e-01],\n",
       "        [-2.6464e+00],\n",
       "        [-1.7534e+00],\n",
       "        [ 3.6862e+00],\n",
       "        [ 2.2287e+00],\n",
       "        [-6.1660e-02],\n",
       "        [-3.2785e+00],\n",
       "        [ 1.2833e+00],\n",
       "        [ 6.8450e-01],\n",
       "        [ 3.8257e+00],\n",
       "        [-1.6803e-01],\n",
       "        [-2.9509e+00],\n",
       "        [ 4.8378e-01],\n",
       "        [ 1.2861e-01],\n",
       "        [ 3.1848e+00],\n",
       "        [ 1.9907e+00],\n",
       "        [ 6.1435e+00],\n",
       "        [ 3.2274e+00],\n",
       "        [ 1.5595e-01],\n",
       "        [ 1.4834e+00],\n",
       "        [ 5.2740e-01],\n",
       "        [-1.5019e+00],\n",
       "        [ 8.0226e-01],\n",
       "        [ 2.9068e+00],\n",
       "        [-6.9011e-01],\n",
       "        [ 1.2157e+00],\n",
       "        [-1.1850e+00],\n",
       "        [ 3.4763e-01],\n",
       "        [-8.8320e-01],\n",
       "        [ 2.5079e+00],\n",
       "        [ 3.7419e-01],\n",
       "        [ 1.8305e+00],\n",
       "        [ 7.1764e+00],\n",
       "        [-4.0200e-01],\n",
       "        [ 1.6595e+00],\n",
       "        [-1.7947e-01],\n",
       "        [ 1.6356e+00],\n",
       "        [ 3.6735e+00],\n",
       "        [ 2.9437e+00],\n",
       "        [-1.8972e+00],\n",
       "        [ 2.7908e-02],\n",
       "        [-1.2332e+00],\n",
       "        [ 3.7722e+00],\n",
       "        [ 3.1884e+00],\n",
       "        [ 2.5609e+00],\n",
       "        [-5.7032e+00],\n",
       "        [-1.0254e+00],\n",
       "        [ 2.9246e+00],\n",
       "        [ 6.6810e-01],\n",
       "        [ 3.3937e+00],\n",
       "        [ 2.6867e+00],\n",
       "        [ 3.2779e+00],\n",
       "        [ 2.4712e+00],\n",
       "        [ 5.4572e-01],\n",
       "        [ 2.8364e+00],\n",
       "        [ 1.7477e+00],\n",
       "        [-1.9919e+00],\n",
       "        [-2.5766e+00],\n",
       "        [ 2.3304e+00],\n",
       "        [ 1.8466e+00],\n",
       "        [ 8.4831e-01],\n",
       "        [ 2.7465e+00],\n",
       "        [ 2.7991e+00],\n",
       "        [-1.1837e+00],\n",
       "        [ 2.9547e+00],\n",
       "        [ 4.8557e-01],\n",
       "        [-5.3915e-01],\n",
       "        [ 1.4279e+00],\n",
       "        [ 1.8394e-01],\n",
       "        [-1.4841e+00],\n",
       "        [ 9.9976e-01],\n",
       "        [ 1.1277e+00],\n",
       "        [ 5.7284e-01],\n",
       "        [-9.5462e-01],\n",
       "        [ 6.3942e-02],\n",
       "        [-9.5550e-01],\n",
       "        [ 9.8961e-01],\n",
       "        [ 3.3685e+00],\n",
       "        [ 1.2262e+00],\n",
       "        [ 1.3798e+00],\n",
       "        [ 5.5719e+00],\n",
       "        [ 2.1099e+00],\n",
       "        [-1.0400e+00],\n",
       "        [ 2.1808e+00],\n",
       "        [ 2.6846e+00],\n",
       "        [ 2.7794e+00],\n",
       "        [-6.9684e-01],\n",
       "        [ 2.0285e+00],\n",
       "        [-3.4012e+00],\n",
       "        [ 1.7980e+00],\n",
       "        [ 1.2829e+00],\n",
       "        [ 1.0652e-01],\n",
       "        [ 9.4051e-01],\n",
       "        [ 4.7830e+00],\n",
       "        [-1.0551e+00],\n",
       "        [ 3.2331e+00],\n",
       "        [ 1.0180e+00],\n",
       "        [ 1.7618e+00],\n",
       "        [ 1.6824e+00],\n",
       "        [-5.9598e-01],\n",
       "        [-3.3086e-01],\n",
       "        [ 4.3085e-01],\n",
       "        [-2.0450e+00],\n",
       "        [ 5.8807e-01],\n",
       "        [ 1.3846e+00],\n",
       "        [ 5.5749e+00],\n",
       "        [-1.1637e+00],\n",
       "        [ 2.8659e+00],\n",
       "        [ 8.6568e-01],\n",
       "        [ 3.7061e+00],\n",
       "        [ 3.3458e+00],\n",
       "        [ 2.7676e+00],\n",
       "        [ 2.2809e+00],\n",
       "        [ 3.9640e+00],\n",
       "        [-8.3383e-01],\n",
       "        [-4.0092e-01],\n",
       "        [ 3.8483e+00],\n",
       "        [ 2.0049e+00],\n",
       "        [-1.3692e+00],\n",
       "        [-2.3819e+00],\n",
       "        [-1.2504e-01],\n",
       "        [ 5.7875e+00],\n",
       "        [-2.1723e+00],\n",
       "        [ 2.9702e+00],\n",
       "        [ 1.4559e+00],\n",
       "        [-1.7663e+00],\n",
       "        [ 1.6293e+00],\n",
       "        [-4.2516e-01],\n",
       "        [ 5.2575e+00],\n",
       "        [-1.8885e+00],\n",
       "        [-2.7328e+00],\n",
       "        [-3.8488e+00],\n",
       "        [-9.4295e-01],\n",
       "        [-1.3798e+00],\n",
       "        [-1.6145e-01],\n",
       "        [-1.6230e+00],\n",
       "        [ 5.5532e-01],\n",
       "        [ 4.0581e+00],\n",
       "        [-7.3849e-02],\n",
       "        [-6.5114e-01],\n",
       "        [-2.5629e+00],\n",
       "        [ 9.5926e-01],\n",
       "        [ 1.5075e+00],\n",
       "        [-6.6593e-01],\n",
       "        [ 2.3918e+00],\n",
       "        [-9.6939e-02],\n",
       "        [-1.6641e+00],\n",
       "        [-3.0509e+00],\n",
       "        [ 1.3175e+00],\n",
       "        [ 3.4038e+00],\n",
       "        [ 9.3493e-01],\n",
       "        [-8.4189e-01],\n",
       "        [-1.1204e+00],\n",
       "        [-5.7423e-01],\n",
       "        [ 2.1631e+00],\n",
       "        [ 1.5883e-01],\n",
       "        [ 1.5961e+00],\n",
       "        [ 2.4116e+00],\n",
       "        [ 1.6952e-01],\n",
       "        [ 2.1952e-01],\n",
       "        [-1.2117e+00],\n",
       "        [ 9.8198e-01],\n",
       "        [ 5.3756e-01],\n",
       "        [ 2.4235e+00],\n",
       "        [-5.3830e-01],\n",
       "        [-7.7480e-01],\n",
       "        [ 1.2437e+00],\n",
       "        [ 3.2141e-01],\n",
       "        [ 1.0576e+00],\n",
       "        [-1.3878e+00],\n",
       "        [ 2.9861e+00],\n",
       "        [ 1.7978e+00],\n",
       "        [ 1.6018e+00],\n",
       "        [-8.4108e-01],\n",
       "        [ 1.7261e-01],\n",
       "        [ 2.0685e-01],\n",
       "        [ 1.6089e+00],\n",
       "        [ 1.4498e+00],\n",
       "        [ 2.8335e+00],\n",
       "        [-1.0564e+00],\n",
       "        [ 3.9306e+00],\n",
       "        [ 3.2032e+00],\n",
       "        [-2.1514e+00],\n",
       "        [ 1.6137e+00],\n",
       "        [ 3.7799e+00],\n",
       "        [ 1.7209e+00],\n",
       "        [ 2.7919e+00],\n",
       "        [-2.1385e+00],\n",
       "        [-9.1988e-01],\n",
       "        [-1.1222e+00],\n",
       "        [ 4.1183e+00],\n",
       "        [-1.0077e+00],\n",
       "        [-4.0801e-02],\n",
       "        [ 1.4198e+00],\n",
       "        [ 4.5516e-01],\n",
       "        [ 3.0093e+00],\n",
       "        [ 9.6620e-01],\n",
       "        [ 6.6300e-01],\n",
       "        [-3.2778e+00],\n",
       "        [-4.8502e-01],\n",
       "        [ 2.2923e+00],\n",
       "        [ 3.1684e+00],\n",
       "        [ 9.9021e-01],\n",
       "        [ 2.4190e+00],\n",
       "        [ 2.1137e+00],\n",
       "        [ 2.5685e+00],\n",
       "        [ 1.0601e+00],\n",
       "        [-1.6876e+00],\n",
       "        [-1.0093e-01],\n",
       "        [ 4.4118e-01],\n",
       "        [ 1.9948e+00],\n",
       "        [-1.2674e+00],\n",
       "        [ 3.1094e+00],\n",
       "        [ 1.7661e+00],\n",
       "        [ 1.6241e+00],\n",
       "        [-1.7055e+00],\n",
       "        [-8.7558e-01],\n",
       "        [ 7.4977e-01],\n",
       "        [ 1.1171e+00],\n",
       "        [-1.1937e-01],\n",
       "        [-1.8004e+00],\n",
       "        [ 2.5201e+00],\n",
       "        [ 5.5662e+00],\n",
       "        [ 2.6555e+00],\n",
       "        [ 4.3230e+00],\n",
       "        [ 3.7898e-01],\n",
       "        [ 4.3282e-01],\n",
       "        [ 2.3208e-01],\n",
       "        [ 9.9198e-01],\n",
       "        [-2.7607e+00],\n",
       "        [-6.9306e-01],\n",
       "        [ 1.1910e+00],\n",
       "        [-1.0042e+00],\n",
       "        [ 1.6128e+00],\n",
       "        [ 1.6264e+00],\n",
       "        [-1.2760e+00],\n",
       "        [-1.2612e+00],\n",
       "        [ 1.9175e+00],\n",
       "        [ 3.0227e+00],\n",
       "        [-3.5556e-02],\n",
       "        [ 5.2238e+00],\n",
       "        [ 5.2975e+00],\n",
       "        [-1.6055e+00],\n",
       "        [ 7.2551e+00],\n",
       "        [ 1.5052e+00],\n",
       "        [ 1.1342e+00],\n",
       "        [ 1.4382e+00],\n",
       "        [-5.1078e-01],\n",
       "        [-2.6675e+00],\n",
       "        [ 2.0057e-01],\n",
       "        [-6.2801e+00],\n",
       "        [ 2.1518e+00],\n",
       "        [ 1.8875e+00],\n",
       "        [ 3.8343e+00],\n",
       "        [ 1.7142e+00],\n",
       "        [-2.3906e-02],\n",
       "        [-3.8784e-01],\n",
       "        [ 6.3085e+00],\n",
       "        [ 1.8861e+00],\n",
       "        [-6.9997e-01],\n",
       "        [ 7.0214e-01],\n",
       "        [ 1.6916e+00],\n",
       "        [ 2.6037e+00],\n",
       "        [ 5.1832e+00],\n",
       "        [ 1.6939e+00],\n",
       "        [ 6.2394e-02],\n",
       "        [-1.7053e+00],\n",
       "        [-2.5665e+00],\n",
       "        [ 1.2553e+00],\n",
       "        [ 1.4051e+00],\n",
       "        [ 4.3313e+00],\n",
       "        [ 1.9724e+00],\n",
       "        [-9.7732e-01],\n",
       "        [-3.5979e+00],\n",
       "        [-1.0273e+00],\n",
       "        [ 1.3028e+00],\n",
       "        [ 4.8363e+00],\n",
       "        [-1.7214e+00],\n",
       "        [ 2.6419e+00],\n",
       "        [ 8.2102e-01],\n",
       "        [ 2.7693e+00],\n",
       "        [-2.6379e-01],\n",
       "        [ 4.4854e+00],\n",
       "        [ 1.0252e+00],\n",
       "        [ 5.0836e+00],\n",
       "        [ 2.1608e+00],\n",
       "        [-1.3026e+00],\n",
       "        [ 3.0730e+00],\n",
       "        [-2.7764e-01],\n",
       "        [ 9.3131e-01],\n",
       "        [ 1.2252e+00],\n",
       "        [ 1.2769e+00],\n",
       "        [-1.0359e+00],\n",
       "        [ 7.2720e-01],\n",
       "        [-2.1850e+00],\n",
       "        [-1.5091e+00],\n",
       "        [ 1.0465e+00],\n",
       "        [ 4.9220e-01],\n",
       "        [-5.8972e-01],\n",
       "        [-8.8701e-01],\n",
       "        [ 3.2925e+00],\n",
       "        [ 2.0600e+00],\n",
       "        [ 3.8884e+00],\n",
       "        [ 2.0713e+00],\n",
       "        [-4.2138e+00],\n",
       "        [ 1.6000e+00],\n",
       "        [ 7.4632e+00],\n",
       "        [ 2.3851e+00],\n",
       "        [ 4.3262e+00],\n",
       "        [-8.5155e-01],\n",
       "        [ 4.4822e+00],\n",
       "        [ 7.4347e-01],\n",
       "        [ 3.5848e-03],\n",
       "        [ 1.8410e+00],\n",
       "        [ 4.9387e-01],\n",
       "        [ 4.5958e+00],\n",
       "        [ 1.5948e+00],\n",
       "        [ 1.0776e+00],\n",
       "        [-4.6241e-01],\n",
       "        [ 3.0907e+00],\n",
       "        [-4.4502e-01],\n",
       "        [-4.7873e-01],\n",
       "        [-1.2899e+00],\n",
       "        [-3.6759e-01],\n",
       "        [ 4.8300e-01],\n",
       "        [ 1.6694e+00],\n",
       "        [-1.1058e+00],\n",
       "        [-1.5774e-01],\n",
       "        [-4.1796e+00],\n",
       "        [ 8.1604e-01],\n",
       "        [-3.5859e-01],\n",
       "        [ 2.4796e+00],\n",
       "        [ 2.6519e+00],\n",
       "        [ 6.2422e+00],\n",
       "        [-1.0323e+00],\n",
       "        [ 1.3090e+00],\n",
       "        [-9.8641e-01],\n",
       "        [-1.7379e+00],\n",
       "        [ 1.7790e+00],\n",
       "        [-7.5182e-01],\n",
       "        [ 2.9519e-01],\n",
       "        [ 1.0277e+00],\n",
       "        [ 1.9957e-01],\n",
       "        [ 1.8730e-02],\n",
       "        [ 3.5109e+00],\n",
       "        [ 1.5336e+00],\n",
       "        [-3.5899e+00],\n",
       "        [ 5.5146e-01],\n",
       "        [ 2.0185e+00],\n",
       "        [ 9.0811e-01],\n",
       "        [ 2.0605e+00],\n",
       "        [-1.2391e+00],\n",
       "        [-2.9734e-01],\n",
       "        [ 3.6075e+00],\n",
       "        [-1.3415e+00],\n",
       "        [ 3.5240e+00],\n",
       "        [ 4.6051e+00],\n",
       "        [ 2.6849e+00],\n",
       "        [-3.2952e+00],\n",
       "        [-1.7300e+00],\n",
       "        [-9.5466e-01],\n",
       "        [ 6.1910e-01],\n",
       "        [ 1.0403e+00],\n",
       "        [ 5.9173e+00],\n",
       "        [ 2.1918e+00],\n",
       "        [ 8.1355e-01],\n",
       "        [ 7.3629e-01],\n",
       "        [ 2.2301e+00],\n",
       "        [ 3.5561e+00],\n",
       "        [-1.5015e+00],\n",
       "        [ 2.3782e+00],\n",
       "        [ 1.6807e+00],\n",
       "        [-1.2408e+00],\n",
       "        [ 1.1585e+00],\n",
       "        [ 2.1024e+00],\n",
       "        [-3.7811e+00],\n",
       "        [-3.0201e+00],\n",
       "        [ 1.4569e+00],\n",
       "        [ 8.1534e-01],\n",
       "        [ 2.0640e+00],\n",
       "        [-3.0288e+00],\n",
       "        [-1.7039e+00],\n",
       "        [-5.2862e-01],\n",
       "        [-3.4043e+00],\n",
       "        [ 5.1064e-01],\n",
       "        [ 5.3970e+00],\n",
       "        [-1.2954e+00],\n",
       "        [-1.2131e+00],\n",
       "        [ 2.9491e+00],\n",
       "        [ 1.2664e+00],\n",
       "        [ 1.4940e+00],\n",
       "        [-1.2948e+00],\n",
       "        [ 9.3775e-01],\n",
       "        [ 5.3518e+00],\n",
       "        [ 2.2205e+00],\n",
       "        [ 1.8419e+00],\n",
       "        [ 2.4415e+00],\n",
       "        [-6.1323e-01],\n",
       "        [-1.7991e+00],\n",
       "        [ 1.3282e+00],\n",
       "        [ 3.1418e+00],\n",
       "        [-3.5430e+00],\n",
       "        [ 4.1476e-01],\n",
       "        [-7.4519e-01],\n",
       "        [ 1.3250e+00],\n",
       "        [ 5.0016e-01],\n",
       "        [ 2.9520e+00],\n",
       "        [ 5.5095e-01],\n",
       "        [-1.6538e+00],\n",
       "        [ 4.8246e+00],\n",
       "        [-2.9954e+00],\n",
       "        [ 1.2296e+00],\n",
       "        [ 2.4661e+00],\n",
       "        [ 2.2219e-02],\n",
       "        [ 1.9525e+00],\n",
       "        [ 6.5162e-01],\n",
       "        [ 1.1183e+00],\n",
       "        [ 5.2490e-01],\n",
       "        [ 2.8464e+00],\n",
       "        [ 1.5024e+00],\n",
       "        [-9.6524e-01],\n",
       "        [-1.4516e+00],\n",
       "        [ 3.3874e+00],\n",
       "        [ 4.6463e+00],\n",
       "        [ 5.3794e+00],\n",
       "        [ 3.7319e+00],\n",
       "        [ 3.6324e-01],\n",
       "        [ 3.8884e+00],\n",
       "        [-1.4583e-01],\n",
       "        [-2.4385e+00],\n",
       "        [-6.1594e-01],\n",
       "        [ 3.1368e+00],\n",
       "        [ 1.8553e+00],\n",
       "        [-3.0963e+00],\n",
       "        [ 3.2664e+00],\n",
       "        [-2.4521e+00],\n",
       "        [-3.1796e+00],\n",
       "        [ 3.0407e+00],\n",
       "        [-1.4830e+00],\n",
       "        [-1.4485e+00],\n",
       "        [-2.1534e+00],\n",
       "        [ 4.0918e+00],\n",
       "        [-2.3005e+00],\n",
       "        [ 2.0446e+00],\n",
       "        [-2.2714e+00],\n",
       "        [ 1.7069e+00],\n",
       "        [-7.3087e-01],\n",
       "        [ 4.7447e+00]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取训练数据集的标签\n",
    "tensorGenReg_dataset[tensorGenReg_dataset_train.indices][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "88faa6c5-ad73-4ad2-bc35-1a6710e02a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[891,\n",
       " 309,\n",
       " 94,\n",
       " 350,\n",
       " 137,\n",
       " 164,\n",
       " 515,\n",
       " 791,\n",
       " 942,\n",
       " 965,\n",
       " 276,\n",
       " 385,\n",
       " 54,\n",
       " 73,\n",
       " 574,\n",
       " 104,\n",
       " 435,\n",
       " 657,\n",
       " 196,\n",
       " 124,\n",
       " 434,\n",
       " 753,\n",
       " 589,\n",
       " 138,\n",
       " 933,\n",
       " 413,\n",
       " 787,\n",
       " 994,\n",
       " 808,\n",
       " 874,\n",
       " 936,\n",
       " 357,\n",
       " 572,\n",
       " 573,\n",
       " 325,\n",
       " 584,\n",
       " 457,\n",
       " 159,\n",
       " 346,\n",
       " 646,\n",
       " 92,\n",
       " 675,\n",
       " 707,\n",
       " 29,\n",
       " 642,\n",
       " 712,\n",
       " 301,\n",
       " 577,\n",
       " 303,\n",
       " 423,\n",
       " 656,\n",
       " 466,\n",
       " 853,\n",
       " 52,\n",
       " 789,\n",
       " 358,\n",
       " 948,\n",
       " 624,\n",
       " 361,\n",
       " 845,\n",
       " 302,\n",
       " 145,\n",
       " 462,\n",
       " 709,\n",
       " 158,\n",
       " 225,\n",
       " 684,\n",
       " 972,\n",
       " 894,\n",
       " 115,\n",
       " 226,\n",
       " 793,\n",
       " 886,\n",
       " 911,\n",
       " 93,\n",
       " 412,\n",
       " 811,\n",
       " 964,\n",
       " 962,\n",
       " 666,\n",
       " 817,\n",
       " 33,\n",
       " 608,\n",
       " 113,\n",
       " 866,\n",
       " 28,\n",
       " 940,\n",
       " 167,\n",
       " 469,\n",
       " 663,\n",
       " 747,\n",
       " 757,\n",
       " 59,\n",
       " 375,\n",
       " 569,\n",
       " 621,\n",
       " 67,\n",
       " 614,\n",
       " 620,\n",
       " 959,\n",
       " 902,\n",
       " 474,\n",
       " 136,\n",
       " 560,\n",
       " 254,\n",
       " 74,\n",
       " 539,\n",
       " 140,\n",
       " 14,\n",
       " 961,\n",
       " 21,\n",
       " 31,\n",
       " 326,\n",
       " 278,\n",
       " 588,\n",
       " 87,\n",
       " 241,\n",
       " 130,\n",
       " 605,\n",
       " 331,\n",
       " 188,\n",
       " 593,\n",
       " 197,\n",
       " 453,\n",
       " 415,\n",
       " 784,\n",
       " 951,\n",
       " 815,\n",
       " 144,\n",
       " 833,\n",
       " 888,\n",
       " 643,\n",
       " 380,\n",
       " 266,\n",
       " 788,\n",
       " 798,\n",
       " 550,\n",
       " 264,\n",
       " 25,\n",
       " 514,\n",
       " 103,\n",
       " 432,\n",
       " 4,\n",
       " 922,\n",
       " 917,\n",
       " 698,\n",
       " 440,\n",
       " 838,\n",
       " 235,\n",
       " 543,\n",
       " 58,\n",
       " 763,\n",
       " 64,\n",
       " 404,\n",
       " 208,\n",
       " 126,\n",
       " 984,\n",
       " 627,\n",
       " 341,\n",
       " 482,\n",
       " 353,\n",
       " 204,\n",
       " 259,\n",
       " 556,\n",
       " 988,\n",
       " 320,\n",
       " 477,\n",
       " 222,\n",
       " 512,\n",
       " 414,\n",
       " 175,\n",
       " 779,\n",
       " 645,\n",
       " 781,\n",
       " 840,\n",
       " 985,\n",
       " 429,\n",
       " 97,\n",
       " 701,\n",
       " 349,\n",
       " 730,\n",
       " 987,\n",
       " 230,\n",
       " 163,\n",
       " 459,\n",
       " 365,\n",
       " 500,\n",
       " 430,\n",
       " 394,\n",
       " 9,\n",
       " 359,\n",
       " 107,\n",
       " 75,\n",
       " 248,\n",
       " 722,\n",
       " 802,\n",
       " 86,\n",
       " 30,\n",
       " 45,\n",
       " 116,\n",
       " 669,\n",
       " 859,\n",
       " 244,\n",
       " 740,\n",
       " 122,\n",
       " 50,\n",
       " 905,\n",
       " 809,\n",
       " 848,\n",
       " 846,\n",
       " 865,\n",
       " 575,\n",
       " 748,\n",
       " 263,\n",
       " 966,\n",
       " 525,\n",
       " 17,\n",
       " 250,\n",
       " 697,\n",
       " 119,\n",
       " 904,\n",
       " 468,\n",
       " 494,\n",
       " 521,\n",
       " 91,\n",
       " 800,\n",
       " 351,\n",
       " 280,\n",
       " 597,\n",
       " 18,\n",
       " 102,\n",
       " 523,\n",
       " 551,\n",
       " 399,\n",
       " 443,\n",
       " 218,\n",
       " 203,\n",
       " 641,\n",
       " 147,\n",
       " 914,\n",
       " 295,\n",
       " 720,\n",
       " 658,\n",
       " 397,\n",
       " 714,\n",
       " 766,\n",
       " 578,\n",
       " 336,\n",
       " 166,\n",
       " 760,\n",
       " 835,\n",
       " 508,\n",
       " 636,\n",
       " 354,\n",
       " 541,\n",
       " 557,\n",
       " 736,\n",
       " 192,\n",
       " 742,\n",
       " 839,\n",
       " 892,\n",
       " 968,\n",
       " 206,\n",
       " 283,\n",
       " 383,\n",
       " 261,\n",
       " 535,\n",
       " 618,\n",
       " 498,\n",
       " 836,\n",
       " 857,\n",
       " 123,\n",
       " 585,\n",
       " 212,\n",
       " 214,\n",
       " 723,\n",
       " 696,\n",
       " 727,\n",
       " 240,\n",
       " 687,\n",
       " 733,\n",
       " 271,\n",
       " 481,\n",
       " 205,\n",
       " 463,\n",
       " 182,\n",
       " 433,\n",
       " 27,\n",
       " 692,\n",
       " 105,\n",
       " 930,\n",
       " 366,\n",
       " 679,\n",
       " 425,\n",
       " 812,\n",
       " 426,\n",
       " 232,\n",
       " 652,\n",
       " 681,\n",
       " 381]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取测试数据集中所有样本的索引\n",
    "tensorGenReg_dataset_test.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6a2787b8-745c-4f3b-abd9-9fbc6f6f4c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算测试数据集中的样本的个数\n",
    "m_test\n",
    "len(tensorGenReg_dataset_test.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19f6bf54-cfaa-4d7d-9574-e4f82b8f3bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.8211e-02, -5.1450e-02],\n",
       "        [ 4.6462e-01,  1.3366e+00],\n",
       "        [-6.1968e-01,  2.2003e+00],\n",
       "        [ 4.3708e-01,  1.0480e+00],\n",
       "        [-5.8773e-01,  1.1988e+00],\n",
       "        [-1.1467e+00,  1.6580e+00],\n",
       "        [ 4.8640e-01, -1.4378e+00],\n",
       "        [-3.2476e-01, -4.4531e-01],\n",
       "        [ 3.4006e-02,  8.9708e-01],\n",
       "        [ 2.3880e+00,  7.6120e-02],\n",
       "        [ 3.0358e-01, -7.1283e-01],\n",
       "        [ 1.8411e+00, -1.2790e-01],\n",
       "        [ 2.2414e+00, -1.7890e-01],\n",
       "        [ 1.3317e-01, -8.2861e-02],\n",
       "        [ 1.5354e+00,  1.6788e-01],\n",
       "        [ 1.0467e+00, -2.0846e+00],\n",
       "        [ 4.7122e-01,  1.3181e+00],\n",
       "        [-5.1967e-01,  7.2717e-02],\n",
       "        [-6.6854e-01,  2.5426e-01],\n",
       "        [ 4.0616e-01, -1.1293e+00],\n",
       "        [-5.9000e-01, -5.9733e-02],\n",
       "        [-6.0702e-01,  1.8217e+00],\n",
       "        [ 2.5376e+00, -1.0975e+00],\n",
       "        [ 1.4540e+00, -6.2552e-01],\n",
       "        [ 1.4293e+00, -1.4599e+00],\n",
       "        [ 1.4707e+00, -1.5748e-01],\n",
       "        [ 8.2696e-01, -1.0996e+00],\n",
       "        [-3.7688e-01, -7.6461e-01],\n",
       "        [ 1.7960e-01,  1.3585e+00],\n",
       "        [-1.3741e+00,  1.8122e-01],\n",
       "        [-5.3525e-01,  2.6685e-02],\n",
       "        [ 1.8950e-01,  1.0693e-01],\n",
       "        [ 1.2992e+00,  1.5435e+00],\n",
       "        [-1.5059e+00,  9.5492e-01],\n",
       "        [-4.6910e-02, -5.4899e-01],\n",
       "        [ 8.0878e-01,  6.4688e-01],\n",
       "        [ 1.6923e+00,  6.7988e-01],\n",
       "        [-5.0358e-01,  1.9305e-01],\n",
       "        [-1.9605e-02, -8.4831e-01],\n",
       "        [ 1.2322e+00, -4.8707e-01],\n",
       "        [ 2.4786e+00,  9.6859e-01],\n",
       "        [ 1.0172e+00,  5.0653e-01],\n",
       "        [-1.5052e+00,  3.3025e-01],\n",
       "        [ 1.8621e+00, -1.0426e+00],\n",
       "        [ 5.4058e-01, -1.7973e+00],\n",
       "        [-4.8335e-01, -1.0188e+00],\n",
       "        [ 8.8713e-01,  3.0009e-01],\n",
       "        [ 4.0602e-01, -1.5720e+00],\n",
       "        [-7.2120e-01, -9.2160e-02],\n",
       "        [-6.5799e-01, -3.2735e-01],\n",
       "        [-1.2503e-01,  1.9895e+00],\n",
       "        [-4.6882e-02,  6.0376e-01],\n",
       "        [ 4.9022e-01, -3.5723e-01],\n",
       "        [-1.1872e+00, -1.2518e+00],\n",
       "        [-9.0181e-01, -1.9284e+00],\n",
       "        [-1.1630e+00,  1.0757e+00],\n",
       "        [ 2.0283e+00,  7.3969e-01],\n",
       "        [-1.0114e+00,  2.2534e-01],\n",
       "        [-2.2090e+00,  1.6229e+00],\n",
       "        [-3.6578e-01,  4.6024e-01],\n",
       "        [-6.4386e-01,  5.3630e-01],\n",
       "        [-6.4750e-01,  1.5559e+00],\n",
       "        [-2.3326e-02,  1.0112e+00],\n",
       "        [ 2.2630e+00, -4.1119e-01],\n",
       "        [ 2.0659e+00, -1.4236e+00],\n",
       "        [-1.1604e+00, -1.0043e+00],\n",
       "        [-4.6758e-01, -3.6282e-01],\n",
       "        [-1.3329e-01, -1.0830e+00],\n",
       "        [-9.0830e-01, -2.7131e-01],\n",
       "        [-2.3157e-01,  1.2002e+00],\n",
       "        [ 1.1151e+00, -4.8279e-01],\n",
       "        [-1.5796e-01, -2.2716e-01],\n",
       "        [-8.2949e-01, -1.3662e+00],\n",
       "        [-1.1251e+00,  9.0874e-01],\n",
       "        [ 2.8554e-01, -9.6329e-01],\n",
       "        [-8.0376e-01, -1.8229e+00],\n",
       "        [ 1.0019e+00,  6.9983e-01],\n",
       "        [-2.2125e-01,  1.9608e+00],\n",
       "        [ 8.3311e-01, -3.4800e-01],\n",
       "        [ 4.7742e-01,  1.6094e-01],\n",
       "        [ 4.9067e-01,  7.6833e-01],\n",
       "        [ 1.7672e-01, -1.8010e+00],\n",
       "        [ 1.7256e-01, -5.5431e-01],\n",
       "        [-2.3623e-01, -1.6196e+00],\n",
       "        [-1.0087e+00,  2.2727e-01],\n",
       "        [ 9.2540e-01, -1.1157e+00],\n",
       "        [-7.6788e-01,  3.5473e-01],\n",
       "        [ 5.9066e-01, -1.5446e+00],\n",
       "        [ 8.5682e-01,  1.6279e+00],\n",
       "        [ 1.0132e+00, -1.6391e+00],\n",
       "        [-3.6477e-01,  2.8909e-03],\n",
       "        [-9.1115e-01,  2.5431e+00],\n",
       "        [ 1.0233e+00,  3.4340e-01],\n",
       "        [-3.3156e-01,  6.9702e-01],\n",
       "        [ 7.6155e-01, -4.0271e-01],\n",
       "        [ 4.2417e-01,  1.0612e+00],\n",
       "        [ 4.6302e-01,  2.6357e+00],\n",
       "        [-2.4890e-01, -8.7553e-01],\n",
       "        [-6.8858e-01, -2.0766e-01],\n",
       "        [ 6.6799e-01, -1.4705e+00],\n",
       "        [ 3.8441e-01, -4.5731e-01],\n",
       "        [-1.6144e+00, -5.7502e-01],\n",
       "        [ 2.4657e-02, -4.5992e-02],\n",
       "        [ 1.4912e+00,  1.0217e+00],\n",
       "        [-8.2236e-03, -1.7326e-01],\n",
       "        [-1.6577e+00, -4.1839e-01],\n",
       "        [ 2.5502e+00,  9.5649e-01],\n",
       "        [ 6.1298e-01,  2.1305e+00],\n",
       "        [-3.2127e-01,  1.7001e+00],\n",
       "        [-1.5916e+00, -1.1328e+00],\n",
       "        [-5.9573e-01, -6.5737e-01],\n",
       "        [-1.3817e-01, -1.0294e+00],\n",
       "        [-1.7136e-01, -1.1379e+00],\n",
       "        [ 6.3814e-01,  3.5759e-02],\n",
       "        [-1.8906e+00,  6.7420e-01],\n",
       "        [ 1.3393e-01, -1.7320e+00],\n",
       "        [-1.9877e+00,  4.4663e-01],\n",
       "        [ 8.4570e-01, -2.6711e-02],\n",
       "        [ 1.1355e+00, -1.0575e+00],\n",
       "        [-1.3709e+00, -5.5890e-01],\n",
       "        [-3.5299e-01,  2.1399e-01],\n",
       "        [-1.2480e-01,  1.3679e+00],\n",
       "        [-1.3758e-01, -3.8408e-01],\n",
       "        [ 3.8558e-02, -1.8034e-01],\n",
       "        [ 3.2276e-01, -2.2915e+00],\n",
       "        [-4.4483e-01,  1.4165e+00],\n",
       "        [ 6.8264e-01,  6.7339e-01],\n",
       "        [ 3.9432e-01, -7.8334e-01],\n",
       "        [ 9.1212e-01, -1.3030e-01],\n",
       "        [ 4.5856e-01, -9.4630e-01],\n",
       "        [ 5.2694e-01, -2.8695e-01],\n",
       "        [-1.1877e-01,  5.9581e-01],\n",
       "        [ 5.5462e-01, -1.5380e-01],\n",
       "        [-1.7266e+00, -1.2163e+00],\n",
       "        [-2.3696e-01,  3.4867e-01],\n",
       "        [ 1.1210e+00, -1.2637e-02],\n",
       "        [-2.4084e+00, -2.1162e+00],\n",
       "        [ 3.5106e-01, -7.8997e-01],\n",
       "        [-2.3159e+00, -7.5265e-01],\n",
       "        [ 6.1205e-01,  4.9692e-01],\n",
       "        [ 1.4797e+00, -4.8181e-01],\n",
       "        [ 2.9734e+00, -9.0278e-01],\n",
       "        [-3.8308e-01,  2.1767e+00],\n",
       "        [ 2.8462e-01, -5.3895e-02],\n",
       "        [ 1.0545e+00,  2.6040e-02],\n",
       "        [ 2.0513e-01, -5.8242e-01],\n",
       "        [-5.7276e-01, -1.0900e+00],\n",
       "        [ 2.2041e-01,  8.2597e-01],\n",
       "        [ 1.0740e+00,  1.1942e-01],\n",
       "        [-7.1839e-01,  4.0842e-01],\n",
       "        [-1.2975e+00,  1.9905e+00],\n",
       "        [-8.2117e-01,  1.2165e+00],\n",
       "        [ 1.2525e-01,  1.2324e+00],\n",
       "        [-1.3535e-02, -1.0690e+00],\n",
       "        [-6.1742e-02, -2.2094e-01],\n",
       "        [-6.2676e-01, -2.5906e+00],\n",
       "        [-3.9585e-01,  1.6129e-01],\n",
       "        [ 1.5352e-01, -1.2724e+00],\n",
       "        [ 7.7713e-01, -6.0385e-01],\n",
       "        [ 7.3259e-01,  1.1442e+00],\n",
       "        [ 2.8633e+00, -1.8285e+00],\n",
       "        [ 1.2052e+00,  3.2574e-01],\n",
       "        [-5.7402e-01, -8.3562e-01],\n",
       "        [ 2.3913e-01,  1.5396e+00],\n",
       "        [ 8.3910e-01, -4.0875e-01],\n",
       "        [ 1.2411e+00, -7.9910e-01],\n",
       "        [-6.2692e-01,  7.6452e-01],\n",
       "        [-6.8594e-01, -1.6942e+00],\n",
       "        [ 2.0998e-01,  1.0802e+00],\n",
       "        [ 4.6170e-01, -1.2321e+00],\n",
       "        [ 2.2573e-01,  6.8796e-01],\n",
       "        [-4.9547e-01,  1.1384e+00],\n",
       "        [-2.9797e-01, -3.4409e-01],\n",
       "        [-4.7892e-01,  5.6607e-01],\n",
       "        [-2.8084e-01, -1.1632e+00],\n",
       "        [-9.1189e-01,  1.0230e+00],\n",
       "        [-6.2053e-01, -1.5317e-01],\n",
       "        [-6.9489e-01, -2.4810e-01],\n",
       "        [ 1.0429e+00, -1.8049e-01],\n",
       "        [-5.8862e-01,  1.0538e+00],\n",
       "        [-2.0874e+00,  1.3702e-01],\n",
       "        [ 8.0053e-02,  1.0717e-01],\n",
       "        [-1.1561e+00,  1.1335e+00],\n",
       "        [ 1.7134e-01, -4.8633e-01],\n",
       "        [ 1.1154e+00, -1.2219e+00],\n",
       "        [-5.4399e-01,  9.7518e-02],\n",
       "        [ 1.9862e-01,  1.7316e+00],\n",
       "        [ 1.1846e+00, -1.0367e+00],\n",
       "        [-1.1727e-01,  7.0971e-01],\n",
       "        [-2.3571e-01,  5.4413e-01],\n",
       "        [-2.4888e+00, -1.6914e+00],\n",
       "        [ 1.0315e+00, -1.7870e+00],\n",
       "        [-9.0725e-01, -6.6166e-01],\n",
       "        [-2.3962e-01, -4.0919e-01],\n",
       "        [-2.8951e-01, -1.5827e+00],\n",
       "        [-2.1008e-01, -4.3416e-01],\n",
       "        [-5.4982e-01, -5.9685e-01],\n",
       "        [ 9.9806e-01,  4.9583e-01],\n",
       "        [ 5.8885e-02,  6.6283e-01],\n",
       "        [-1.0072e+00, -6.7986e-01],\n",
       "        [-7.8084e-01, -1.0757e+00],\n",
       "        [-6.6850e-01, -1.4142e+00],\n",
       "        [ 1.6552e+00,  9.9830e-01],\n",
       "        [-2.5302e-01, -2.3853e-01],\n",
       "        [-1.2268e+00, -7.8463e-02],\n",
       "        [-4.9237e-01, -9.0877e-01],\n",
       "        [ 2.1677e+00, -6.8555e-02],\n",
       "        [ 1.1632e+00,  5.1561e-03],\n",
       "        [ 9.6164e-02,  1.2385e-01],\n",
       "        [-3.6901e-01,  1.1206e+00],\n",
       "        [-1.2124e-01, -1.2778e+00],\n",
       "        [-1.5809e+00,  9.7552e-01],\n",
       "        [-1.3436e+00,  1.8906e+00],\n",
       "        [-1.4067e+00, -9.4777e-01],\n",
       "        [-6.0598e-02,  6.4255e-01],\n",
       "        [ 1.4699e+00, -1.3325e+00],\n",
       "        [ 9.9149e-02, -1.0988e+00],\n",
       "        [ 1.3938e+00,  2.4735e-01],\n",
       "        [ 1.2202e+00, -1.8012e-01],\n",
       "        [ 7.4244e-02, -1.2429e-01],\n",
       "        [ 1.6436e+00,  2.1086e+00],\n",
       "        [-1.9172e+00, -1.9295e+00],\n",
       "        [-7.2148e-01, -1.8882e-01],\n",
       "        [ 5.4768e-01,  2.0906e-01],\n",
       "        [-1.3049e+00, -8.5936e-02],\n",
       "        [ 7.6453e-01,  9.7712e-01],\n",
       "        [-1.8208e-01, -3.6154e-01],\n",
       "        [ 9.0368e-02,  2.1729e-01],\n",
       "        [ 7.2844e-02,  1.4521e-01],\n",
       "        [ 5.7439e-02,  8.9280e-01],\n",
       "        [-1.3234e+00, -5.0467e-01],\n",
       "        [ 1.4800e+00, -3.7060e-01],\n",
       "        [ 1.6709e+00, -1.6637e+00],\n",
       "        [ 1.6767e-01,  2.2416e-01],\n",
       "        [ 1.4520e-01,  1.2099e+00],\n",
       "        [-4.8733e-01,  1.1737e-01],\n",
       "        [ 2.5059e+00,  4.4976e-01],\n",
       "        [ 1.1747e-01,  2.0683e+00],\n",
       "        [-8.7538e-02,  3.1583e+00],\n",
       "        [ 7.0816e-01, -1.2517e+00],\n",
       "        [-1.1082e+00,  6.1463e-01],\n",
       "        [ 4.0212e-01,  3.1376e-01],\n",
       "        [ 1.1179e+00,  4.7143e-01],\n",
       "        [ 1.0778e+00,  1.2139e+00],\n",
       "        [ 1.1568e+00,  1.2878e+00],\n",
       "        [ 7.1337e-01, -1.6411e+00],\n",
       "        [ 1.4547e+00, -3.0180e-01],\n",
       "        [-1.1697e+00, -6.5203e-01],\n",
       "        [-2.4249e-01, -1.6320e+00],\n",
       "        [-8.7874e-01, -9.1643e-01],\n",
       "        [ 3.4205e-01, -3.8927e-01],\n",
       "        [-4.4803e-01, -9.8819e-01],\n",
       "        [-8.3954e-03,  8.9331e-01],\n",
       "        [-1.3975e+00,  6.8005e-01],\n",
       "        [ 1.3895e+00,  2.6188e+00],\n",
       "        [ 2.4145e-01,  7.5091e-02],\n",
       "        [ 6.7422e-01,  1.3242e+00],\n",
       "        [-1.4189e-02,  1.0747e+00],\n",
       "        [-9.9245e-01, -8.4907e-01],\n",
       "        [ 8.3332e-01, -2.3862e-01],\n",
       "        [-2.2935e-01,  4.8000e-01],\n",
       "        [ 3.0849e-01,  9.6014e-01],\n",
       "        [ 2.8368e-01, -1.4446e-02],\n",
       "        [ 1.1483e+00, -1.3726e+00],\n",
       "        [-4.6007e-01,  1.7381e+00],\n",
       "        [-4.1980e-02,  5.9843e-01],\n",
       "        [ 4.0830e-01, -3.8467e-01],\n",
       "        [-1.4379e+00,  4.6168e-01],\n",
       "        [ 6.8055e-01, -7.4908e-01],\n",
       "        [-5.0670e-01,  4.1595e-01],\n",
       "        [ 1.5829e+00, -8.6685e-01],\n",
       "        [-1.8179e-02,  1.9779e+00],\n",
       "        [-8.3143e-02, -1.2909e+00],\n",
       "        [-1.8928e-02, -1.0551e+00],\n",
       "        [-8.7841e-01, -1.3360e-01],\n",
       "        [ 4.7737e-01, -9.0348e-01],\n",
       "        [-1.3674e+00, -2.2344e-01],\n",
       "        [ 6.0939e-01, -3.3279e-01],\n",
       "        [ 1.1254e-01, -1.8240e-02],\n",
       "        [-1.3530e+00,  5.6764e-01],\n",
       "        [ 3.6133e-02, -1.4503e+00],\n",
       "        [ 2.3915e-01, -4.0561e-01],\n",
       "        [ 5.4246e-01, -9.2884e-01],\n",
       "        [-3.6068e-01,  7.5724e-01],\n",
       "        [-2.5336e-01,  2.2909e-01],\n",
       "        [ 7.5422e-01, -1.6480e+00],\n",
       "        [ 1.3240e+00,  1.4569e-01],\n",
       "        [-3.0537e-01,  8.5887e-02],\n",
       "        [-9.1428e-01, -8.9956e-02],\n",
       "        [ 1.0261e+00, -8.4955e-01],\n",
       "        [ 5.2319e-01, -1.0450e+00],\n",
       "        [-1.7234e+00,  1.4507e+00],\n",
       "        [-6.8253e-01, -3.4244e-01],\n",
       "        [ 6.1466e-01,  1.4275e-01],\n",
       "        [ 1.5604e+00, -1.9055e+00],\n",
       "        [ 2.3796e-01,  7.7337e-01],\n",
       "        [ 2.2060e-01, -2.9596e-01],\n",
       "        [-1.3154e+00,  5.1849e-01],\n",
       "        [ 1.1706e+00, -3.5023e-01],\n",
       "        [ 5.7835e-01, -2.2274e-01]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从完整的数据集中获取测试数据集的特征变量\n",
    "type(tensorGenReg_dataset[tensorGenReg_dataset_test.indices])\n",
    "tensorGenReg_dataset[tensorGenReg_dataset_test.indices][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c73b7702-47d0-4853-a8d2-c80281b593e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1620e+00],\n",
       "        [ 6.0929e-01],\n",
       "        [-2.4364e+00],\n",
       "        [ 8.2079e-01],\n",
       "        [-1.3746e+00],\n",
       "        [-2.9598e+00],\n",
       "        [ 3.4135e+00],\n",
       "        [ 8.0084e-01],\n",
       "        [ 1.6233e-01],\n",
       "        [ 5.6999e+00],\n",
       "        [ 2.3170e+00],\n",
       "        [ 4.8210e+00],\n",
       "        [ 5.6624e+00],\n",
       "        [ 1.3540e+00],\n",
       "        [ 3.9118e+00],\n",
       "        [ 5.1700e+00],\n",
       "        [ 6.1217e-01],\n",
       "        [-1.1722e-01],\n",
       "        [-5.8309e-01],\n",
       "        [ 2.9415e+00],\n",
       "        [-1.0880e-01],\n",
       "        [-2.0310e+00],\n",
       "        [ 7.1820e+00],\n",
       "        [ 4.5214e+00],\n",
       "        [ 5.3191e+00],\n",
       "        [ 4.1136e+00],\n",
       "        [ 3.7490e+00],\n",
       "        [ 1.0243e+00],\n",
       "        [-9.0587e-03],\n",
       "        [-1.9143e+00],\n",
       "        [-1.1169e-01],\n",
       "        [ 1.2634e+00],\n",
       "        [ 2.0642e+00],\n",
       "        [-2.9665e+00],\n",
       "        [ 1.4585e+00],\n",
       "        [ 1.9635e+00],\n",
       "        [ 3.6952e+00],\n",
       "        [-2.0270e-01],\n",
       "        [ 1.8054e+00],\n",
       "        [ 3.9434e+00],\n",
       "        [ 4.9823e+00],\n",
       "        [ 2.5413e+00],\n",
       "        [-2.3590e+00],\n",
       "        [ 5.7631e+00],\n",
       "        [ 3.8799e+00],\n",
       "        [ 1.0498e+00],\n",
       "        [ 2.4782e+00],\n",
       "        [ 3.3958e+00],\n",
       "        [-3.6796e-01],\n",
       "        [ 4.5404e-03],\n",
       "        [-1.2316e+00],\n",
       "        [ 2.8600e-01],\n",
       "        [ 2.3355e+00],\n",
       "        [-1.2305e-01],\n",
       "        [ 1.1240e+00],\n",
       "        [-2.4164e+00],\n",
       "        [ 4.3329e+00],\n",
       "        [-1.2540e+00],\n",
       "        [-5.0336e+00],\n",
       "        [-1.7576e-01],\n",
       "        [-8.2753e-01],\n",
       "        [-1.8804e+00],\n",
       "        [-8.1802e-02],\n",
       "        [ 5.9372e+00],\n",
       "        [ 6.5584e+00],\n",
       "        [-3.1361e-01],\n",
       "        [ 4.2737e-01],\n",
       "        [ 1.8102e+00],\n",
       "        [-5.3480e-01],\n",
       "        [-6.6158e-01],\n",
       "        [ 3.7221e+00],\n",
       "        [ 9.0942e-01],\n",
       "        [ 7.0040e-01],\n",
       "        [-2.1622e+00],\n",
       "        [ 2.5167e+00],\n",
       "        [ 1.2118e+00],\n",
       "        [ 2.3015e+00],\n",
       "        [-1.4060e+00],\n",
       "        [ 2.9918e+00],\n",
       "        [ 1.8020e+00],\n",
       "        [ 1.2042e+00],\n",
       "        [ 3.1456e+00],\n",
       "        [ 1.8982e+00],\n",
       "        [ 2.1442e+00],\n",
       "        [-1.2568e+00],\n",
       "        [ 3.9779e+00],\n",
       "        [-8.9571e-01],\n",
       "        [ 3.7182e+00],\n",
       "        [ 1.0900e+00],\n",
       "        [ 4.6700e+00],\n",
       "        [ 2.5146e-01],\n",
       "        [-3.3773e+00],\n",
       "        [ 2.7077e+00],\n",
       "        [-3.4780e-01],\n",
       "        [ 2.9135e+00],\n",
       "        [ 7.8552e-01],\n",
       "        [-7.0449e-01],\n",
       "        [ 1.3832e+00],\n",
       "        [-1.8190e-01],\n",
       "        [ 3.7971e+00],\n",
       "        [ 2.2041e+00],\n",
       "        [-1.6537e+00],\n",
       "        [ 1.0884e+00],\n",
       "        [ 2.9745e+00],\n",
       "        [ 1.1517e+00],\n",
       "        [-1.9056e+00],\n",
       "        [ 5.1341e+00],\n",
       "        [ 8.8123e-02],\n",
       "        [-1.3411e+00],\n",
       "        [-1.0598e+00],\n",
       "        [ 4.7310e-01],\n",
       "        [ 1.7473e+00],\n",
       "        [ 1.8030e+00],\n",
       "        [ 2.2318e+00],\n",
       "        [-3.4544e+00],\n",
       "        [ 3.0119e+00],\n",
       "        [-3.4299e+00],\n",
       "        [ 2.7123e+00],\n",
       "        [ 4.3420e+00],\n",
       "        [-1.1794e+00],\n",
       "        [ 6.5911e-02],\n",
       "        [-6.1820e-01],\n",
       "        [ 1.1067e+00],\n",
       "        [ 1.2724e+00],\n",
       "        [ 3.9398e+00],\n",
       "        [-1.3138e+00],\n",
       "        [ 1.6836e+00],\n",
       "        [ 2.5739e+00],\n",
       "        [ 2.9581e+00],\n",
       "        [ 2.8561e+00],\n",
       "        [ 2.3412e+00],\n",
       "        [ 1.5329e-01],\n",
       "        [ 2.2553e+00],\n",
       "        [-1.2262e+00],\n",
       "        [ 1.8035e-01],\n",
       "        [ 3.2628e+00],\n",
       "        [-1.7117e+00],\n",
       "        [ 2.4811e+00],\n",
       "        [-2.8829e+00],\n",
       "        [ 1.7341e+00],\n",
       "        [ 4.4361e+00],\n",
       "        [ 7.8497e+00],\n",
       "        [-1.9446e+00],\n",
       "        [ 1.6189e+00],\n",
       "        [ 3.0925e+00],\n",
       "        [ 2.0057e+00],\n",
       "        [ 9.3870e-01],\n",
       "        [ 6.1354e-01],\n",
       "        [ 3.0254e+00],\n",
       "        [-8.2631e-01],\n",
       "        [-3.5820e+00],\n",
       "        [-1.8437e+00],\n",
       "        [ 1.4530e-02],\n",
       "        [ 2.0472e+00],\n",
       "        [ 1.1167e+00],\n",
       "        [ 2.3413e+00],\n",
       "        [ 3.9604e-02],\n",
       "        [ 2.5682e+00],\n",
       "        [ 3.1512e+00],\n",
       "        [ 1.3091e+00],\n",
       "        [ 8.5506e+00],\n",
       "        [ 3.0831e+00],\n",
       "        [ 6.9238e-01],\n",
       "        [-8.0259e-02],\n",
       "        [ 3.0790e+00],\n",
       "        [ 4.2719e+00],\n",
       "        [-1.0087e+00],\n",
       "        [ 1.3094e+00],\n",
       "        [ 3.3773e-01],\n",
       "        [ 3.1460e+00],\n",
       "        [ 7.5686e-01],\n",
       "        [-1.1214e+00],\n",
       "        [ 7.5426e-01],\n",
       "        [-5.1815e-01],\n",
       "        [ 1.6094e+00],\n",
       "        [-1.8397e+00],\n",
       "        [-9.2120e-02],\n",
       "        [-1.3455e-01],\n",
       "        [ 3.2924e+00],\n",
       "        [-1.2337e+00],\n",
       "        [-3.3183e+00],\n",
       "        [ 1.0505e+00],\n",
       "        [-2.4475e+00],\n",
       "        [ 1.8328e+00],\n",
       "        [ 4.4700e+00],\n",
       "        [-1.8362e-01],\n",
       "        [-3.3035e-01],\n",
       "        [ 4.3969e+00],\n",
       "        [ 6.0717e-02],\n",
       "        [-2.8245e-02],\n",
       "        [-2.3066e+00],\n",
       "        [ 4.8579e+00],\n",
       "        [-1.5487e-01],\n",
       "        [ 9.1955e-01],\n",
       "        [ 1.9963e+00],\n",
       "        [ 1.0151e+00],\n",
       "        [ 4.8499e-01],\n",
       "        [ 2.4994e+00],\n",
       "        [ 4.4615e-01],\n",
       "        [-3.3451e-01],\n",
       "        [ 5.1959e-01],\n",
       "        [ 1.0527e+00],\n",
       "        [ 3.3195e+00],\n",
       "        [ 7.3554e-01],\n",
       "        [-1.3642e+00],\n",
       "        [ 9.3202e-01],\n",
       "        [ 5.4012e+00],\n",
       "        [ 3.3216e+00],\n",
       "        [ 1.0759e+00],\n",
       "        [-8.7731e-01],\n",
       "        [ 2.0360e+00],\n",
       "        [-3.1553e+00],\n",
       "        [-3.5749e+00],\n",
       "        [-8.5474e-01],\n",
       "        [ 2.3868e-01],\n",
       "        [ 5.2831e+00],\n",
       "        [ 2.2962e+00],\n",
       "        [ 3.5389e+00],\n",
       "        [ 3.6141e+00],\n",
       "        [ 1.2667e+00],\n",
       "        [ 2.1725e+00],\n",
       "        [-9.0527e-01],\n",
       "        [-2.5438e-01],\n",
       "        [ 1.8736e+00],\n",
       "        [-1.5252e+00],\n",
       "        [ 1.5605e+00],\n",
       "        [ 1.0018e+00],\n",
       "        [ 9.7015e-01],\n",
       "        [ 1.0039e+00],\n",
       "        [ 2.2133e-01],\n",
       "        [-1.1434e+00],\n",
       "        [ 4.3200e+00],\n",
       "        [ 6.0089e+00],\n",
       "        [ 1.1014e+00],\n",
       "        [ 7.8066e-02],\n",
       "        [-9.5477e-02],\n",
       "        [ 5.5400e+00],\n",
       "        [-8.3025e-01],\n",
       "        [-2.3195e+00],\n",
       "        [ 3.6709e+00],\n",
       "        [-1.8262e+00],\n",
       "        [ 1.4915e+00],\n",
       "        [ 2.7688e+00],\n",
       "        [ 1.9342e+00],\n",
       "        [ 2.0188e+00],\n",
       "        [ 4.0653e+00],\n",
       "        [ 4.2098e+00],\n",
       "        [-6.7744e-01],\n",
       "        [ 2.1391e+00],\n",
       "        [ 1.5622e-01],\n",
       "        [ 2.0608e+00],\n",
       "        [ 1.0886e+00],\n",
       "        [ 9.4063e-02],\n",
       "        [-2.4669e+00],\n",
       "        [ 1.1586e+00],\n",
       "        [ 1.4155e+00],\n",
       "        [ 1.0329e+00],\n",
       "        [-1.0860e-01],\n",
       "        [-1.6195e-01],\n",
       "        [ 2.9101e+00],\n",
       "        [ 6.0319e-02],\n",
       "        [ 6.6284e-01],\n",
       "        [ 1.5810e+00],\n",
       "        [ 4.6647e+00],\n",
       "        [-1.6615e+00],\n",
       "        [ 2.9784e-01],\n",
       "        [ 2.2080e+00],\n",
       "        [-2.3562e+00],\n",
       "        [ 3.1152e+00],\n",
       "        [-4.3636e-01],\n",
       "        [ 5.0383e+00],\n",
       "        [-9.9164e-01],\n",
       "        [ 2.1248e+00],\n",
       "        [ 2.0318e+00],\n",
       "        [-6.0522e-01],\n",
       "        [ 2.8802e+00],\n",
       "        [-1.5172e+00],\n",
       "        [ 2.5565e+00],\n",
       "        [ 1.2498e+00],\n",
       "        [-2.2674e+00],\n",
       "        [ 2.5308e+00],\n",
       "        [ 1.8933e+00],\n",
       "        [ 3.0115e+00],\n",
       "        [-4.7118e-01],\n",
       "        [ 2.6581e-01],\n",
       "        [ 4.1620e+00],\n",
       "        [ 3.5083e+00],\n",
       "        [ 3.0732e-01],\n",
       "        [-7.3623e-01],\n",
       "        [ 3.8913e+00],\n",
       "        [ 3.1101e+00],\n",
       "        [-3.9073e+00],\n",
       "        [-2.7197e-02],\n",
       "        [ 2.0779e+00],\n",
       "        [ 6.0237e+00],\n",
       "        [ 7.1459e-01],\n",
       "        [ 1.7272e+00],\n",
       "        [-2.1365e+00],\n",
       "        [ 3.6920e+00],\n",
       "        [ 2.3865e+00]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从完整的数据集中获取测试数据集的标签\n",
    "tensorGenReg_dataset[tensorGenReg_dataset_test.indices][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7d7da3a-283b-4b86-aaa2-34b694af59c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.7497e-05, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算完成训练后的模型在训练数据集上的损失函数\n",
    "loss_train = criterion(net(tensorGenReg_dataset[tensorGenReg_dataset_train.indices][0]), tensorGenReg_dataset[tensorGenReg_dataset_train.indices][1])\n",
    "loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0cea3ddb-b404-49d1-8fc7-62f81e9bca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.8828e-05, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算完成训练后的模型在测试数据集上的损失函数\n",
    "loss_test = criterion(net(tensorGenReg_dataset[tensorGenReg_dataset_test.indices][0]), tensorGenReg_dataset[tensorGenReg_dataset_test.indices][1])\n",
    "loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b36f673-c187-4c0d-9af7-5a47032a0544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "def split_loader(X, y, rate=0.7, batch_size=10):\n",
    "    \"\"\"\n",
    "    先将一个完整的数据集按照给定的比例划分为训练数据集和测试数据集\n",
    "    再将训练数据集和测试数据集分别按照给定的大小分别划分为互不相交的子集合\n",
    "    @param X: 特征变量\n",
    "    @param y: 标签\n",
    "    @param rate: 训练数据集中的样本数占完整数据集中的样本数的比例\n",
    "    @param batch_size: 用于划分子集合的数据集的大小\n",
    "\n",
    "    @return 批处理化后的训练数据集和测试数据集\n",
    "    \"\"\"\n",
    "    # 1.计算一个完整的数据集包含的样本个数 => 标量\n",
    "    m = len(X)\n",
    "    # 2.计算训练数据集中包含的样本的个数 = 完整的数据集中包含的样本的个数 * 训练数据集中的样本数占完整数据集中的样本数的比例\n",
    "    m_train = int(m * rate)\n",
    "    # 3.计算测试数据集中包含的样本的个数 = 完整的数据集中包含的样本的个素 - 训练数据集中的样本数\n",
    "    m_test = m - m_train\n",
    "    # 4.将一个完整的数据集按照给定的比例划分为训练数据集和测试数据集\n",
    "    dataset = tensorGenRegDataset(X=X, y=y)\n",
    "    dataset_train, dataset_test = random_split(dataset=dataset, lengths=[m_train, m_test])\n",
    "\n",
    "    # 5.将训练数据集和测试数据集分别按照给定的大小分别划分为互不相交的子集合\n",
    "    batched_dataset_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    batched_dataset_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return batched_dataset_train, batched_dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a4c3db-e5ed-4d72-a834-fdd22f521b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1280e0550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 加载原始的数据集\n",
    "X, y = tensorGenReg()\n",
    "X = X[:, :-1]\n",
    "\n",
    "# 加载批处理后的训练数据集和测试数据集\n",
    "batched_dataset_train, batched_dataset_test = split_loader(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca356b1a-e13b-4e87-a579-acc0443cbd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batched_dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6beacf4b-8a45-451c-8bdd-fe4b16501733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1662, 0.2457]), tensor([1.0714]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset_train.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b93f8452-7e32-475f-94ff-516804513e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看训练数据集中样本的个数\n",
    "# len(batched_dataset_train.dataset[:])\n",
    "len(batched_dataset_train.dataset[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e5b5b3-bfb7-4fc4-b356-3892ccb6a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(dataset, model):\n",
    "    \"\"\"对一个完成训练流程的模型, 计算模型在训练数据集或测试数据集上的MSE\n",
    "    @param dataset: 训练数据集or测试数据集\n",
    "    @param model: 一个已经完成训练流程的模型\n",
    "    \"\"\"\n",
    "    # 1.从完整的数据集中获取样本的特征变量和标签\n",
    "    X = dataset.dataset[:][0]\n",
    "    y = dataset.dataset[:][1]\n",
    "    # 2.前向传播, 计算模型以当前的参数对数据集进行学习后的预测输出标记\n",
    "    z_hat = model.forward(X)\n",
    "    # 3.计算损失, 计算模型的预测输出标记和真实标签之间的误差\n",
    "    loss = F.mse_loss(z_hat, y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4869559-4119-439f-aa5c-b14000eb7b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1662,  0.2457],\n",
       "        [-2.3092,  2.1917],\n",
       "        [-0.2503,  1.6936],\n",
       "        ...,\n",
       "        [ 0.8131,  0.9148],\n",
       "        [-0.9485, -0.1682],\n",
       "        [ 2.0251,  0.3138]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset_train.dataset[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7f7d73-b134-4fc9-becf-a15eaca22b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(n_epochs, batched_dataset, model, criterion, optimizer, task=\"reg\"):\n",
    "        \"\"\"让模型拟合数据, 在训练过程中更新模型的参数, 使得损失函数值减小, 尽可能最小\n",
    "        @param n_epochs: 对于一个完整的数据集进行学习的遍数\n",
    "        @param batched_dataset: 将一个完整的数据集按照指定的样本容量划分为若干个互不相交的子集\n",
    "        @param model: 模型\n",
    "        @param criterion: 损失函数\n",
    "        @param optimizer: 优化器\n",
    "\n",
    "        @return: 完成训练流程的模型(不一定是性能最好的模型)\n",
    "        \"\"\"\n",
    "        for i_epoch in range(n_epochs):\n",
    "            for (i_X, i_y) in batched_dataset:\n",
    "                # 1.前向传播, 计算以当前的模型参数对该批次的数据进行学习, 模型的预测输出标记\n",
    "                z_hat = model.forward(i_X)\n",
    "                # 2.计算损失, 计算模型的预测输出标记与真实标签之间的误差, 构建完整的计算图\n",
    "                if task == \"clf\":\n",
    "                    i_y = i_y.flatten().long()\n",
    "                    \n",
    "                loss = criterion(z_hat, i_y)\n",
    "                # 3.反向传播, 计算以当前的模型参数对应的偏导函数表达式和值, 以确定各个模型的参数在对应维度上应该向哪个方向进行更新(该维度所在的正方向or负方向)\n",
    "                loss.backward()\n",
    "                # 4.更新模型的参数, 优化器根据梯度信息, 计算当前的模型参数在各个维度的已知方向上应该更新的数值\n",
    "                optimizer.step()\n",
    "                # 5.清空梯度信息\n",
    "                optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a019e8-23ed-45d7-83fc-98d883c6c7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x126c58550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GeoffNet(\n",
       "  (output_linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 加载原始的数据集\n",
    "X, y = tensorGenReg()\n",
    "X = X[:, :-1]\n",
    "\n",
    "# 加载批处理后的训练数据集和测试数据集\n",
    "batched_dataset_train, batched_dataset_test = split_loader(X=X, y=y)\n",
    "\n",
    "# 实例化模型\n",
    "net\n",
    "\n",
    "# 选择合适的损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 选择合适的优化器\n",
    "eta = 0.03\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=eta)\n",
    "\n",
    "# 训练模型\n",
    "fit(n_epochs=3, batched_dataset=batched_dataset_train, model=net, criterion=criterion, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5609f464-53bb-4030-9400-8a49471b7388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeoffNet(\n",
       "  (output_linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看完成训练的模型\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a98d81-4bc4-4a23-9335-fc09015c38dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.7814e-05, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算完成训练的模型在训练数据集上的损失函数的数值\n",
    "calc_mse(dataset=batched_dataset_train, model=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "338b3d10-ac87-4e90-95d2-baf85eaf6c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(batched_dataset_train.dataset[0])\n",
    "# len(batched_dataset_train.dataset[:][0])\n",
    "len(batched_dataset_train.dataset[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e26d51cd-3206-4d99-8b88-622d3981cf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.9001e-05, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算完成训练的模型在测试数据集上的损失函数的数值\n",
    "calc_mse(dataset=batched_dataset_test, model=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1718111c-f692-43f6-8546-7d513d2ebabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(dataset, model):\n",
    "    \"\"\"对一个完成训练的模型, 计算模型在训练数据集或者测试数据集上的分类准确度\n",
    "    @param dataset: 训练数据集或者测试数据集\n",
    "    @param model: 完成训练的模型\n",
    "    @return 模型在训练数据集或者测试数据集上的分类准确度\n",
    "    \"\"\"\n",
    "    # 1.计算数据集中样本的总数\n",
    "    # m = len(dataset.dataset[:][0])\n",
    "    # 2.计算模型在当前数据集上的预测输出标记\n",
    "    # model.forward(dataset.data[:][0])\n",
    "\n",
    "    # 获取数据集中的特征变量\n",
    "    X = dataset.dataset[:][0]\n",
    "    # 获取数据集中的标签\n",
    "    y = dataset.dataset[:][1]\n",
    "    # 计算模型在当前数据集上的预测输出标记\n",
    "    z_hat = model.forward(X)\n",
    "    sigma = F.softmax(z_hat, dim=1)\n",
    "    is_correct = torch.argmax(input=sigma, dim=1).flatten() == y.flatten()\n",
    "    # 计算分类准确度\n",
    "    accuracy = torch.mean(is_correct.float())\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "115b40ae-3a60-4f01-8f24-5ef5e7d3be07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在计算机的内存中一次性存储数值0~8, 选择数据结构张量 => 确定张量的维度和各个维度上的形状, 张量的数据类型由元素的数据类型确定\n",
    "t = torch.arange(start=0, end=9, step=1).reshape(3, 3).float()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "427c60af-77a0-40be-b464-f682aa9ede36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(t, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d5cf3d-7201-4c84-81ee-68f9a59d0f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x126c58550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 加载原始数据集\n",
    "X, y = tensorGenCla()\n",
    "\n",
    "# 将原始数据集划分为训练数据集和测试数据集, 同时将分别将训练和测试数据集按照指定的大小划分为若干个互不相交的子集\n",
    "dataset_train, dataset_test = split_loader(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aec3212-9a29-4bac-aa46-59dd00e7515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x126c58550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搭建深度神经网络模型架构\n",
    "torch.manual_seed(55)\n",
    "\n",
    "# 搭建深度神经网络模型的架构\n",
    "# 搭建模型: 使用面向对象(定义类/创建对象)的方式 继承nn.Module类\n",
    "class GeoffNet(nn.Module):\n",
    "    # 构造器 + 类/对象属性\n",
    "    # => 子类的对象调用父类的构造器\n",
    "    # => 神经网络模型中的各种层\n",
    "    def __init__(self, in_features=2, out_features=3, bias=False):\n",
    "        super(GeoffNet, self).__init__()\n",
    "\n",
    "        self.output_linear = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "\n",
    "    # 方法\n",
    "    # => 前向传播: 数据从神经网络的输入层 -> 隐藏层 -> 输出层; 逐层完成整合信息+加工信息\n",
    "    def forward(self, X):\n",
    "        # 输入层 -> 输出层\n",
    "        # 整合信息\n",
    "        z_hat = self.output_linear(X)\n",
    "        # 加工信息\n",
    "        # sigma = F.softmax(z_hat)\n",
    "        # return sigma\n",
    "        return z_hat\n",
    "\n",
    "# 实例化模型\n",
    "net = GeoffNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c5078cd-fd69-4625-9f11-7758e329e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x126c58550>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 选择合适的损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 选择合适的优化器\n",
    "eta = 0.03\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41a3bfed-5c2a-4c07-849a-d0fda3a7e753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x126c58550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 训练模型\n",
    "fit(n_epochs=3, batched_dataset=dataset_train, model=net, criterion=criterion, optimizer=optimizer, task=\"clf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1467be9b-cadc-4abb-bec4-8d89346cffd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8790)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算完成训练的模型在训练数据集上的模型评价指标-分类准确度\n",
    "calc_accuracy(dataset=dataset_train, model=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c1fcdf2-0287-437c-899e-064819419a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8622)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算完成训练的模型在测试数据集上的模型评价指标-分类准确度\n",
    "calc_accuracy(dataset=dataset_test, model=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6328b35-7375-44fd-9434-ff1e230e4432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
