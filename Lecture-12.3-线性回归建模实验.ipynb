{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e3e4a1-4eba-48ab-a9bb-29a1fbb64476",
   "metadata": {},
   "source": [
    "##### 线性回归的手动实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f01e6b6-fe8f-49a9-99c1-0971380b8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模块\n",
    "import random\n",
    "\n",
    "# 加载绘图模块\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载计算模块\n",
    "import numpy as np\n",
    "\n",
    "# 加载深度神经网络算法的核心数据结构与计算模块\n",
    "import torch\n",
    "# =====> 第一部分: 数据\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "# =====> 第二部分: 搭建深度神经网络模型\n",
    "import torch.nn as nn  # 深度神经网络模型中的各种层(内置整合信息的方式)\n",
    "from torch.nn import functional as F  # 深度神经网络模型中的各种基于张量的整合信息和加工信息的方式\n",
    "# =====> 第三部分: 训练深度神经网络模型\n",
    "import torch.optim as optim\n",
    "# =====> 第四部分: 辅助工具\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# 加载自定义模块\n",
    "from torchLearning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2494961d-7a42-4726-89ad-d56a1df3339a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtensorGenReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "回归类任务数据集创建函数:\n",
       "@param num_samples: 数据集中的样本个数\n",
       "@param w: 数据集中特征变量前的权重, 包含截距项\n",
       "@param bias: 是否包含截距项\n",
       "@param delta: 控制噪声的大小\n",
       "@param degree: 每一个特征变量的系数\n",
       "\n",
       "@return: 特征张量X和标签张量y组成的元组\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Desktop/prep_PhD/DL/codes/torchLearning.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorGenReg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc62a8a-0b9d-4394-923f-30ae579c538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(55)\n",
    "X, y = tensorGenReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb0e6302-94e1-45fe-ae75-f9f661276b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看特征张量的维度和形状\n",
    "# X.ndim\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ede75826-7357-434b-af9f-0db581331bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看标签的维度和形状\n",
    "# y.ndim\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f62bfc-f723-44fb-97d6-355cc6723a23",
   "metadata": {},
   "source": [
    "##### 自定义神经网络模型: 直接基于张量的计算完成深度神经网络建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf04d5cd-26d6-426c-baa7-8ec12564b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, w):\n",
    "    return torch.mm(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e48ecc9-10fd-46ab-b603-40fad2d316e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):\n",
    "    # 计算数据集中样本的个数\n",
    "    num_ = y.numel()\n",
    "    # 计算SSE\n",
    "    sse = torch.sum((y_hat.reshape(-1, 1) - y.reshape(-1, 1)) ** 2)\n",
    "    return sse / num_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "00af89b9-3a07-4e4b-876f-75b2ca60d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr):\n",
    "    params.data = params.data - lr * params.grad\n",
    "    params.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53bd202d-7424-4e0e-9a95-98cdd130ef25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(2., requires_grad=True, dtype=torch.float32)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85cb445d-3203-4eb4-b8cb-58347f3bfb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e6e8a72-f8ca-4afb-882b-e45b26cc9173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = w * 2\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71d12133-59c2-4fd6-8bdf-776d51e93e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63f41678-293c-4cc6-b322-08ad71e32610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在Pytorch进行计算的时候, 可以将一个设置了requires_grad=True的张量运算的结果存储在计算机的内存中\n",
    "# 并且给该内存区域起一个其它不同于当前张量的别名\n",
    "w = torch.tensor(2., requires_grad=True, dtype=torch.float32)\n",
    "w1 = w * 2\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e5c1454-ca29-44ad-b1d7-6c86ba2d116f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 但是不可以将计算的结果存储在计算机的内存空间中, 然后给该内存区域起一个当前张量的别名\u001b[39;00m\n\u001b[1;32m      2\u001b[0m w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m2.\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 3\u001b[0m w \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      4\u001b[0m w\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "# 但是不可以将计算的结果存储在计算机的内存空间中, 然后给该内存区域起一个当前张量的别名\n",
    "w = torch.tensor(2., requires_grad=True, dtype=torch.float32)\n",
    "w -= w * 2\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82cd3072-313d-4beb-a32f-5581048d6933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(2., requires_grad=True, dtype=torch.float32)\n",
    "w = w * 2\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6ebaeba-f57d-43ac-ba69-82992618e93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3df0ef03-0fdc-4927-a9fe-0535c8005e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(2., requires_grad=True, dtype=torch.float32)\n",
    "w = w * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3501c8cc-cce8-4567-9929-6ee8d37f92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "135bd828-f0ff-4e2b-b664-573750744e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ht/7tjg01r945gch9nd9n7s7c3c0000gn/T/ipykernel_10257/447174752.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  w.grad\n"
     ]
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "752c3458-c3f3-4be4-b704-93a9f0d3ed9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(2., requires_grad=True, dtype=torch.float32)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "743487e8-bcb0-4747-870a-5c3b5da75b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2., requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w * 2\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2173565b-d0fe-4a95-a51c-ec2acc6ec98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e03fffe-d24e-4bdb-af77-ada39114ae10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(2., requires_grad=True, dtype=torch.float32)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5cc08964-6c51-4dcd-898a-8c394c5ca704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.detach_()  # 从计算图中移除了该叶子节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afd67ce7-b3b3-46ee-a77c-63615e328645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "168d6183-2728-4df9-a168-46a097a03bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w -= w * 2\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a7b8673-064c-4145-b7e0-5f6bb89e0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad7edcd3-b7e0-47c2-ae2a-971927cbde0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2., requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "884485a5-1401-4c88-a5a2-46b4447e95a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33910eaf-53b1-4823-88c4-54297d82d08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(2., requires_grad=True, dtype=torch.float32)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14c580aa-9c15-418b-b9a1-e9c5d7283b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f84a812b-2531-47e4-b9b8-0026d1e713c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43d60852-f583-4e43-91d3-9fc6d8935618",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.data -= w * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1694f6f0-32ef-47a4-8905-bf731db769fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2., requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fa463ad-7ae9-4ecc-bfb9-0e1f5c786e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15f7c5e9-0596-4e77-b3af-18e8275e4098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "921ba5c8-30b1-4816-9a3e-db22e11f902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 加载数据\n",
    "X, y = tensorGenReg()\n",
    "\n",
    "# 将完整的数据集按照一定的大小划分为若干个互不相交的子数据集\n",
    "batch_size = 10\n",
    "batched_dataset = split_dataset(batch_size=batch_size, X=X, y=y)\n",
    "# 设置将完整的数据集学习的次数\n",
    "n_epochs = 3\n",
    "# 设置优化器的参数\n",
    "eta = 0.03\n",
    "# 随机初始化模型的参数\n",
    "w = torch.zeros(size=(X.shape[1], 1), requires_grad=True, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ab8b428-7c4e-4154-b1b1-147fcbadfb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "将完整的数据集(特征张量, 标签)按照相同的大小, 划分为若干个互不相交的子集\n",
       "@param batch_size: 每一个子数据集中样本的个数\n",
       "@param X: 包含所有样本的特征张量\n",
       "@param y: 包含所有样本的标签\n",
       "\n",
       "@return batched_dataset: 列表, 包含有一定数量的元组, 每一个元组的第一个元素是子集的特征张量, 第二个元素是子集的标签\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Desktop/prep_PhD/DL/codes/torchLearning.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0e97dfb-7385-4b4f-b355-fcd7fecb1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = linear_regression\n",
    "loss = squared_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "83d10544-d597-4626-a7ed-ec58eb403eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(squared_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1566d839-af10-4b23-addd-da734d3f3f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000119\n",
      "epoch 2, loss 0.000095\n",
      "epoch 3, loss 0.000095\n"
     ]
    }
   ],
   "source": [
    "# 训练深度神经网络模型\n",
    "# 1.将完整的数据集学习多遍\n",
    "for i_epoch in range(n_epochs):\n",
    "    # 2.在每一遍完整学习数据集的时候, 将数据集拆分为若干个互不相交的子集进行学习\n",
    "    for i_batch in batched_dataset:\n",
    "        i_X = i_batch[0]\n",
    "        i_y = i_batch[1]\n",
    "        # 前向传播\n",
    "        y_hat = net(i_X, w)\n",
    "        # 计算损失\n",
    "        l = squared_loss(y_hat, i_y)\n",
    "        # 反向传播\n",
    "        l.backward()\n",
    "        # 使用优化器更新模型的参数\n",
    "        sgd(w, eta)\n",
    "\n",
    "    # 完整学习完一遍数据集之后, 计算当前模型的参数在完整的数据集上的损失\n",
    "    # 前向传播\n",
    "    y_hat = net(X, w)\n",
    "    # 计算损失\n",
    "    l = squared_loss(y_hat, y)\n",
    "    print(\"epoch %d, loss %f\" % (i_epoch+1, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "171c7d66-97df-4621-961d-12a31f143495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0007],\n",
       "        [-0.9996],\n",
       "        [ 0.9996]], requires_grad=True)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "481b48d8-f49f-453c-87bd-f09685094965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tensorboardX模块来记录训练深度神经网络模型过程中核心指标的变化\n",
    "writer = SummaryWriter(logdir=\"./reg_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ed9c319-1dc5-4702-9306-3e1c31ca2cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "torch.manual_seed(55)\n",
    "X, y = tensorGenReg()\n",
    "\n",
    "# 搭建深度神经网络模型\n",
    "net = linear_regression\n",
    "w = torch.zeros(size=(X.shape[1], 1), requires_grad=True)\n",
    "\n",
    "# 训练深度神经网络模型\n",
    "batch_size = 10\n",
    "eta = 0.03\n",
    "# =====> 将完整的数据集训练多遍\n",
    "n_epochs = 3\n",
    "for i_epoch in range(n_epochs):\n",
    "    # =====> 将一个完整的数据集划分为若干个互不相交的子数据集进行训练\n",
    "    for i_batch in split_dataset(batch_size=batch_size, X=X, y=y):\n",
    "        # 获取当前的子数据集中的特征张量和标签\n",
    "        i_X, i_y = i_batch[0], i_batch[1]\n",
    "        # 1.前向传播\n",
    "        y_hat = net(i_X, w)\n",
    "        # 2.计算损失\n",
    "        loss = squared_loss(y_hat, i_y)\n",
    "        # 3.反向传播\n",
    "        loss.backward()\n",
    "        # 4.优化器利用反向传播的信息更新模型的参数\n",
    "        sgd(params=w, lr=eta)\n",
    "    # 将一个完整的数据集学习完一遍后, 计算以当前模型的参数学习完整的数据集的损失函数值\n",
    "    loss = squared_loss(net(X, w), y)\n",
    "    # 使用工具记录关键信息\n",
    "    writer.add_scalar(\"mul\", loss, i_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfbed1-c9b7-4d21-9615-1957ed0c887d",
   "metadata": {},
   "source": [
    "##### =====> 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b6be57ea-85b2-4c63-aba8-e875c18c9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 加载数据集\n",
    "X, y = tensorGenReg()\n",
    "X = X[:, :-1]\n",
    "# 使用TensorDataset类, 将特征张量和标签打包存储在元组中\n",
    "dataset = TensorDataset(X, y)\n",
    "# 设置将一个完整的数据集划分为若干个互不相交的子集的子集大小\n",
    "batch_size = 10\n",
    "# 将一个完整的数据集按照固定的子集大小划分为若干个子集\n",
    "batched_dataset = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e4074-b719-49d3-8215-f655d9fb1535",
   "metadata": {},
   "source": [
    "##### =====> 搭建深度神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "20a48a22-5118-43ce-ace7-d2328cd936d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoffNet(nn.Module):\n",
    "    # 构造器 + 类/对象属性\n",
    "    # => 子类的对象调用父类的构造器\n",
    "    # => 搭建深度神经网络模型的架构\n",
    "    def __init__(self, in_features=2, out_features=1):\n",
    "        super(GeoffNet, self).__init__()\n",
    "\n",
    "        # 输出层\n",
    "        self.output_linear = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "\n",
    "    # 方法\n",
    "    # => 前向传播: 让输入数据经过输入层 -> 隐藏层 -> 输出层; 逐层完成整合信息和加工信息的计算\n",
    "    def forward(self, X):\n",
    "        # 输入层 -> 输出层\n",
    "        # 整合信息\n",
    "        z_hat = self.output_linear(X)\n",
    "        # 加工信息\n",
    "        # output = nn.ReLU(z_hat)\n",
    "        return z_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add62fc-fc90-4b9f-a1f5-2a0ada691c6c",
   "metadata": {},
   "source": [
    "##### =====> 训练深度神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a50f4da3-b55e-478b-b607-6ba7c3124537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "net = GeoffNet()\n",
    "\n",
    "# 选择损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 选择优化器\n",
    "eta = 0.03\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=eta)\n",
    "\n",
    "# 选择可视化工具\n",
    "writer = SummaryWriter(logdir=\"reg_loss2\")\n",
    "\n",
    "# 搭建训练深度神经网络模型的流程\n",
    "# =====> 将完整的数据集训练多遍\n",
    "n_epochs = 3\n",
    "for i_epoch in range(n_epochs):\n",
    "    # =====> 将一个完整的数据集划分为若干个互不相交的子数据集进行训练\n",
    "    for i_X, i_y in batched_dataset:\n",
    "        # 1.前向传播\n",
    "        i_y_hat = net.forward(i_X)\n",
    "        # 2.计算损失\n",
    "        loss = criterion(i_y_hat, i_y)\n",
    "        # 3.利用损失函数的计算图, 反向传播\n",
    "        loss.backward()\n",
    "        # 4.利用反向传播的梯度信息, 使用优化器更新模型的参数\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    # 在将一个完整的数据集训练一遍后, 计算以当前模型的参数进行学习, 得到的损失函数值.\n",
    "    loss = criterion(net(X), y)\n",
    "    writer.add_scalar(\"loss\", loss, global_step=i_epoch)\n",
    "    writer.add_graph(net, (X, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "773ed806-5160-4a91-87a7-502d85ccd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, criterion, optimizer, X, y, n_epochs, batch_size):\n",
    "    \"\"\"搭建训练深度神经网络模型的流程\n",
    "    @param: model, 需要进行训练的模型\n",
    "    @param: criterion, 选择的损失函数\n",
    "    @param: optimizer, 选择的优化器\n",
    "    @param: n_epochs, 将完整的数据集训练多遍\n",
    "    @param: batch_size, 将一个完整的数据集划分为若干个互不相交的子集, 一个子集的大小\n",
    "    @param: X, 特征张量\n",
    "    @param: y, 标签\n",
    "    \"\"\"\n",
    "    # 使用TensorDataset类, 将特征张量和标签打包存储在元组中\n",
    "    dataset = TensorDataset(X, y)\n",
    "    # 将一个完整的数据集按照固定的子集大小划分为若干个子集\n",
    "    batched_dataset = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "        \n",
    "    # 搭建训练深度神经网络模型的流程\n",
    "    # =====> 将完整的数据集训练多遍\n",
    "    for i_epoch in range(n_epochs):\n",
    "        # =====> 将一个完整的数据集划分为若干个互不相交的子数据集进行训练\n",
    "        for i_X, i_y in batched_dataset:\n",
    "            # 1.前向传播\n",
    "            i_y_hat = net.forward(i_X)\n",
    "            # 2.计算损失\n",
    "            loss = criterion(i_y_hat, i_y)\n",
    "            # 3.利用损失函数的计算图, 反向传播\n",
    "            loss.backward()\n",
    "            # 4.利用反向传播的梯度信息, 使用优化器更新模型的参数\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # 在将一个完整的数据集训练一遍后, 计算以当前模型的参数进行学习, 得到的损失函数值.\n",
    "        loss = criterion(net(X), y)\n",
    "        writer.add_scalar(\"loss\", loss, global_step=i_epoch)\n",
    "        writer.add_graph(net, (X, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3abc24d-68dd-465b-a639-90928537e5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeoffNet(\n",
       "  (output_linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "28c77916-10ae-4e30-90e7-0cf679097182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x1286eb450>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "781f1a4e-ac8e-4b99-91fc-291d494622f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.0000, -1.0001]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9997], requires_grad=True)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "33eae357-4f0e-4f06-a299-8c2d249796ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.4451e-05, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算当前训练后的模型, 以当前的模型的参数完整的学习一遍数据集的损失函数的值\n",
    "loss = criterion(net(X), y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69282e32-edf3-469c-9c99-65846fb390f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, (X, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8296cb21-1da9-43e9-bc26-df4a7b162faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "torch.manual_seed(55)\n",
    "\n",
    "X, y = tensorGenReg(degree=2)\n",
    "X = X[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a790f053-8846-42be-ad92-bf7ad4840b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "net = GeoffNet()\n",
    "# 选择损失函数\n",
    "criterion = nn.MSELoss()\n",
    "# 选择优化器\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=0.03)\n",
    "\n",
    "# 训练深度神经网络模型\n",
    "n_epochs = 3\n",
    "batch_size = 10\n",
    "fit(model=net, criterion=criterion, optimizer=optimizer, X=X, y=y, n_epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bcf1467c-7abf-4cb3-af15-66201d1fc5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "搭建训练深度神经网络模型的流程\n",
       "@param: model, 需要进行训练的模型\n",
       "@param: criterion, 选择的损失函数\n",
       "@param: optimizer, 选择的优化器\n",
       "@param: n_epochs, 将完整的数据集训练多遍\n",
       "@param: batch_size, 将一个完整的数据集划分为若干个互不相交的子集, 一个子集的大小\n",
       "@param: X, 特征张量\n",
       "@param: y, 标签\n",
       "\u001b[0;31mFile:\u001b[0m      /var/folders/ht/7tjg01r945gch9nd9n7s7c3c0000gn/T/ipykernel_10257/3386227148.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ed7e830-91f5-4f25-883e-fc05ba51cad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.3560, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(net.forward(X), y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4bc51233-b747-4dee-9fcd-c1ae87d546bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(55)\n",
    "\n",
    "# 加载数据集\n",
    "X, y = tensorGenReg(delta=2)\n",
    "X = X[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b279314c-abe3-4f60-bb31-0edebf963a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "net = GeoffNet()\n",
    "# 选择损失函数\n",
    "criterion = nn.MSELoss()\n",
    "# 选择优化器\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=0.03)\n",
    "\n",
    "# 训练深度神经网络模型\n",
    "n_epochs = 3\n",
    "batch_size = 10\n",
    "fit(model=net, criterion=criterion, optimizer=optimizer, X=X, y=y, n_epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0a7da583-85fb-4ead-8474-710cd05f8c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7781, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(net.forward(X), y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fe26a-8873-40f1-82a9-3915ca709e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
